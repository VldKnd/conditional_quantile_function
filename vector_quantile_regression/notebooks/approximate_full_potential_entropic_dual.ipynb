{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138531b2",
   "metadata": {},
   "source": [
    "Relaxed entropy dual with normal feed forward nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "490bdd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class BetaNetwork(torch.nn.Module):\n",
    "    \"\"\"Input Convex Neural Network for beta potential estimation\"\"\"\n",
    "\n",
    "    def __init__(self, input_dimension: int, hidden_dimension: int, num_hidden_layers: int, output_dimension: int):\n",
    "        super().__init__()\n",
    "\n",
    "        Wzs = []\n",
    "        Wzs.append(nn.Linear(input_dimension, hidden_dimension))\n",
    "        for _ in range(num_hidden_layers - 1):\n",
    "            Wzs.append(torch.nn.Linear(hidden_dimension, hidden_dimension, bias=False))\n",
    "        Wzs.append(torch.nn.Linear(hidden_dimension, 1, bias=False))\n",
    "        self.Wzs = torch.nn.ModuleList(Wzs)\n",
    "\n",
    "        Wxs = []\n",
    "        for _ in range(num_hidden_layers - 1):\n",
    "            Wxs.append(nn.Linear(input_dimension, hidden_dimension))\n",
    "        Wxs.append(nn.Linear(input_dimension, output_dimension, bias=False))\n",
    "        self.Wxs = torch.nn.ModuleList(Wxs)\n",
    "        self.act = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.act(self.Wzs[0](x))\n",
    "        for Wz, Wx in zip(self.Wzs[1:-1], self.Wxs[:-1]):\n",
    "            z = self.act(Wz(z) + Wx(x))\n",
    "        return self.Wzs[-1](z) + self.Wxs[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "915bff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_sphere_uniform(n, d, **kwargs):\n",
    "    \"\"\"Generate n points inside the d-dimensional sphere.\"\"\"\n",
    "    random_vectors = torch.randn(n, d, **kwargs)\n",
    "    vectors_norms = torch.norm(random_vectors, dim=1, keepdim=True)\n",
    "    radius = torch.pow(torch.rand(n, 1, **kwargs), 1. / d)\n",
    "    return radius * random_vectors / vectors_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec1fae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import create_joint_x_y\n",
    "import numpy as np\n",
    "\n",
    "num_points_to_generate = 1000\n",
    "X, Y = create_joint_x_y(num_points_to_generate)\n",
    "\n",
    "n, d = Y.shape\n",
    "m = n\n",
    "\n",
    "nu = np.ones((n, 1)) / n\n",
    "mu = np.ones((m, 1)) / m\n",
    "\n",
    "phi_network = nn.Sequential(\n",
    "    nn.Linear(d + X.shape[1], 100),\n",
    "    nn.Softplus(),\n",
    "    nn.Linear(100, 1)\n",
    ")\n",
    "psi_network = nn.Sequential(\n",
    "    nn.Linear(d + X.shape[1], 100),\n",
    "    nn.Softplus(),\n",
    "    nn.Linear(100, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e63dc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.980641833386947e+232 1 0.1\n",
      "4.851984932076048e+189 2 0.1\n",
      "1.7853498521142356e+122 3 0.1\n",
      "1.3629025184453224e+209 4 0.1\n",
      "2.214996387761339e+206 5 0.1\n",
      "8.35540941658402e+183 6 0.1\n",
      "1.9759875457476822e+225 7 0.1\n",
      "3.4261094151294866e+192 8 0.1\n",
      "1.3990750523265928e+223 9 0.1\n",
      "1.1563997258758548e+145 10 0.1\n",
      "3.685286346518223e+132 11 0.1\n",
      "1.6354936304487727e+236 12 0.1\n",
      "1.5671589772611046e+195 13 0.1\n",
      "2.637994321158932e+193 14 0.1\n",
      "3.399293751657537e+150 15 0.1\n",
      "1.194145639110434e+223 16 0.1\n",
      "1.0624929973901584e+231 17 0.1\n",
      "1.2911163849849394e+212 18 0.1\n",
      "2.114649027973336e+248 19 0.1\n",
      "4.230008692958413e+178 20 0.1\n",
      "8.796835402797164e+291 21 0.1\n",
      "5.29808921911935e+182 22 0.1\n",
      "1.3532892058437442e+158 23 0.1\n",
      "2.1768775695862533e+83 24 0.1\n",
      "1.0109606681348035e+185 25 0.1\n",
      "4.316997076388845e+247 26 0.1\n",
      "5.736233820951026e+150 27 0.1\n",
      "5.830625111810421e+223 28 0.1\n",
      "6.698757482245865e+154 29 0.1\n",
      "1.9224847293735409e+192 30 0.1\n",
      "1.1740243984527957e+255 31 0.1\n",
      "2.090082068009496e+171 32 0.1\n",
      "2.0966474512917523e+182 33 0.1\n",
      "1.322761200660198e+182 34 0.1\n",
      "2.5066310288034827e+227 35 0.1\n",
      "7.910818860598875e+223 36 0.1\n",
      "2.2746992371829332e+184 37 0.1\n",
      "7.19950570295613e+255 38 0.1\n",
      "5.585906936716997e+189 39 0.1\n",
      "2.1774762219139555e+185 40 0.1\n",
      "1.4344226832821069e+217 41 0.1\n",
      "4.182657491247617e+158 42 0.1\n",
      "1.991557641726031e+193 43 0.1\n",
      "3.708865620147314e+252 44 0.1\n",
      "4.839379228941921e+236 45 0.1\n",
      "4.513479759036502e+222 46 0.1\n",
      "2.3799081149834996e+169 47 0.1\n",
      "3.946044985466092e+137 48 0.1\n",
      "2.338536799693592e+206 49 0.1\n",
      "4.886515501978761e+173 50 0.1\n",
      "4.827629399285207e+239 51 0.1\n",
      "1.1021067006887054e+197 52 0.1\n",
      "6.059867567156151e+179 53 0.1\n",
      "2.726263709224947e+192 54 0.1\n",
      "5.184784530791583e+198 55 0.1\n",
      "1.7582043754238936e+186 56 0.1\n",
      "5.552812280377143e+214 57 0.1\n",
      "2.0119144153659377e+161 58 0.1\n",
      "1.683755413095838e+124 59 0.1\n",
      "2.727258102235611e+185 60 0.1\n",
      "6.498169991206308e+205 61 0.1\n",
      "7.67400918959907e+214 62 0.1\n",
      "4.725738082375246e+256 63 0.1\n",
      "1.0603287101934855e+184 64 0.1\n",
      "3.855669994893513e+239 65 0.1\n",
      "3.2528916455944604e+277 66 0.1\n",
      "1.6728815258444776e+190 67 0.1\n",
      "2.786996922710443e+163 68 0.1\n",
      "7.755709376142338e+266 69 0.1\n",
      "1.3405107179143935e+248 70 0.1\n",
      "2.004613703203302e+186 71 0.1\n",
      "8.247397937192275e+152 72 0.1\n",
      "8.072045353752539e+209 73 0.1\n",
      "1.2632894497253125e+199 74 0.1\n",
      "1.1593144010808633e+206 75 0.1\n",
      "1.5332731765245306e+177 76 0.1\n",
      "3.7450402062745765e+194 77 0.1\n",
      "2.3669714962462703e+155 78 0.1\n",
      "6.634836035773417e+213 79 0.1\n",
      "1.1878611360433044e+191 80 0.1\n",
      "3.961631904181473e+200 81 0.1\n",
      "4.013360004625473e+169 82 0.1\n",
      "2.37168464919633e+193 83 0.1\n",
      "6.755103580575028e+166 84 0.1\n",
      "1.022970121128188e+178 85 0.1\n",
      "1.55176842827048e+160 86 0.1\n",
      "2.1638531636328903e+175 87 0.1\n",
      "2.701543366612787e+172 88 0.1\n",
      "3.605412480930625e+162 89 0.1\n",
      "1.5497400249625443e+190 90 0.1\n",
      "5.9434473982141905e+224 91 0.1\n",
      "2.936956904029604e+217 92 0.1\n",
      "5.775463950261656e+216 93 0.1\n",
      "2.166903941783959e+295 94 0.1\n",
      "6.899954793950999e+180 95 0.1\n",
      "4.398959994850727e+198 96 0.1\n",
      "2.530118845269759e+100 97 0.1\n",
      "1.8789138930678602e+206 98 0.1\n",
      "7.27771215231865e+155 99 0.1\n",
      "4.822861613475874e+194 100 0.1\n",
      "3.908219661342662e+150 101 0.1\n",
      "4.9387305049148196e+207 102 0.1\n",
      "1.1726065326178155e+174 103 0.1\n",
      "4.2203813275445896e+167 104 0.1\n",
      "inf 105 0.1\n",
      "nan 106 0.1\n",
      "nan 107 0.1\n",
      "nan 108 0.1\n",
      "nan 109 0.1\n",
      "nan 110 0.1\n",
      "nan 111 0.1\n",
      "nan 112 0.1\n",
      "nan 113 0.1\n",
      "nan 114 0.1\n",
      "nan 115 0.1\n",
      "nan 116 0.1\n",
      "nan 117 0.1\n",
      "nan 118 0.1\n",
      "nan 119 0.1\n",
      "nan 120 0.1\n",
      "nan 121 0.1\n",
      "nan 122 0.1\n",
      "nan 123 0.1\n",
      "nan 124 0.1\n",
      "nan 125 0.1\n",
      "nan 126 0.1\n",
      "nan 127 0.1\n",
      "nan 128 0.1\n",
      "nan 129 0.1\n",
      "nan 130 0.1\n",
      "nan 131 0.1\n",
      "nan 132 0.1\n",
      "nan 133 0.1\n",
      "nan 134 0.1\n",
      "nan 135 0.1\n",
      "nan 136 0.1\n",
      "nan 137 0.1\n",
      "nan 138 0.1\n",
      "nan 139 0.1\n",
      "nan 140 0.1\n",
      "nan 141 0.1\n",
      "nan 142 0.1\n",
      "nan 143 0.1\n",
      "nan 144 0.1\n",
      "nan 145 0.1\n",
      "nan 146 0.1\n",
      "nan 147 0.1\n",
      "nan 148 0.1\n",
      "nan 149 0.1\n",
      "nan 150 0.1\n",
      "nan 151 0.1\n",
      "nan 152 0.1\n",
      "nan 153 0.1\n",
      "nan 154 0.1\n",
      "nan 155 0.1\n",
      "nan 156 0.1\n",
      "nan 157 0.1\n",
      "nan 158 0.1\n",
      "nan 159 0.1\n",
      "nan 160 0.1\n",
      "nan 161 0.1\n",
      "nan 162 0.1\n",
      "nan 163 0.1\n",
      "nan 164 0.1\n",
      "nan 165 0.1\n",
      "nan 166 0.1\n",
      "nan 167 0.1\n",
      "nan 168 0.1\n",
      "nan 169 0.1\n",
      "nan 170 0.1\n",
      "nan 171 0.1\n",
      "nan 172 0.1\n",
      "nan 173 0.1\n",
      "nan 174 0.1\n",
      "nan 175 0.1\n",
      "nan 176 0.1\n",
      "nan 177 0.1\n",
      "nan 178 0.1\n",
      "nan 179 0.1\n",
      "nan 180 0.1\n",
      "nan 181 0.1\n",
      "nan 182 0.1\n",
      "nan 183 0.1\n",
      "nan 184 0.1\n",
      "nan 185 0.1\n",
      "nan 186 0.1\n",
      "nan 187 0.1\n",
      "nan 188 0.1\n",
      "nan 189 0.1\n",
      "nan 190 0.1\n",
      "nan 191 0.1\n",
      "nan 192 0.1\n",
      "nan 193 0.1\n",
      "nan 194 0.1\n",
      "nan 195 0.1\n",
      "nan 196 0.1\n",
      "nan 197 0.1\n",
      "nan 198 0.1\n",
      "nan 199 0.1\n",
      "nan 200 0.1\n",
      "nan 201 0.1\n",
      "nan 202 0.1\n",
      "nan 203 0.1\n",
      "nan 204 0.1\n",
      "nan 205 0.1\n",
      "nan 206 0.1\n",
      "nan 207 0.1\n",
      "nan 208 0.1\n",
      "nan 209 0.1\n",
      "nan 210 0.1\n",
      "nan 211 0.1\n",
      "nan 212 0.1\n",
      "nan 213 0.1\n",
      "nan 214 0.1\n",
      "nan 215 0.1\n",
      "nan 216 0.1\n",
      "nan 217 0.1\n",
      "nan 218 0.1\n",
      "nan 219 0.1\n",
      "nan 220 0.1\n",
      "nan 221 0.1\n",
      "nan 222 0.1\n",
      "nan 223 0.1\n",
      "nan 224 0.1\n",
      "nan 225 0.1\n",
      "nan 226 0.1\n",
      "nan 227 0.1\n",
      "nan 228 0.1\n",
      "nan 229 0.1\n",
      "nan 230 0.1\n",
      "nan 231 0.1\n",
      "nan 232 0.1\n",
      "nan 233 0.1\n",
      "nan 234 0.1\n",
      "nan 235 0.1\n",
      "nan 236 0.1\n",
      "nan 237 0.1\n",
      "nan 238 0.1\n",
      "nan 239 0.1\n",
      "nan 240 0.1\n",
      "nan 241 0.1\n",
      "nan 242 0.1\n",
      "nan 243 0.1\n",
      "nan 244 0.1\n",
      "nan 245 0.1\n",
      "nan 246 0.1\n",
      "nan 247 0.1\n",
      "nan 248 0.1\n",
      "nan 249 0.1\n",
      "nan 250 0.1\n",
      "nan 251 0.1\n",
      "nan 252 0.1\n",
      "nan 253 0.1\n",
      "nan 254 0.1\n",
      "nan 255 0.1\n",
      "nan 256 0.1\n",
      "nan 257 0.1\n",
      "nan 258 0.1\n",
      "nan 259 0.1\n",
      "nan 260 0.1\n",
      "nan 261 0.1\n",
      "nan 262 0.1\n",
      "nan 263 0.1\n",
      "nan 264 0.1\n",
      "nan 265 0.1\n",
      "nan 266 0.1\n",
      "nan 267 0.1\n",
      "nan 268 0.1\n",
      "nan 269 0.1\n",
      "nan 270 0.1\n",
      "nan 271 0.1\n",
      "nan 272 0.1\n",
      "nan 273 0.1\n",
      "nan 274 0.1\n",
      "nan 275 0.1\n",
      "nan 276 0.1\n",
      "nan 277 0.1\n",
      "nan 278 0.1\n",
      "nan 279 0.1\n",
      "nan 280 0.1\n",
      "nan 281 0.1\n",
      "nan 282 0.1\n",
      "nan 283 0.1\n",
      "nan 284 0.1\n",
      "nan 285 0.1\n",
      "nan 286 0.1\n",
      "nan 287 0.1\n",
      "nan 288 0.1\n",
      "nan 289 0.1\n",
      "nan 290 0.1\n",
      "nan 291 0.1\n",
      "nan 292 0.1\n",
      "nan 293 0.1\n",
      "nan 294 0.1\n",
      "nan 295 0.1\n",
      "nan 296 0.1\n",
      "nan 297 0.1\n",
      "nan 298 0.1\n",
      "nan 299 0.1\n",
      "nan 300 0.1\n",
      "nan 301 0.1\n",
      "nan 302 0.1\n",
      "nan 303 0.1\n",
      "nan 304 0.1\n",
      "nan 305 0.1\n",
      "nan 306 0.1\n",
      "nan 307 0.1\n",
      "nan 308 0.1\n",
      "nan 309 0.1\n",
      "nan 310 0.1\n",
      "nan 311 0.1\n",
      "nan 312 0.1\n",
      "nan 313 0.1\n",
      "nan 314 0.1\n",
      "nan 315 0.1\n",
      "nan 316 0.1\n",
      "nan 317 0.1\n",
      "nan 318 0.1\n",
      "nan 319 0.1\n",
      "nan 320 0.1\n",
      "nan 321 0.1\n",
      "nan 322 0.1\n",
      "nan 323 0.1\n",
      "nan 324 0.1\n",
      "nan 325 0.1\n",
      "nan 326 0.1\n",
      "nan 327 0.1\n",
      "nan 328 0.1\n",
      "nan 329 0.1\n",
      "nan 330 0.1\n",
      "nan 331 0.1\n",
      "nan 332 0.1\n",
      "nan 333 0.1\n",
      "nan 334 0.1\n",
      "nan 335 0.1\n",
      "nan 336 0.1\n",
      "nan 337 0.1\n",
      "nan 338 0.1\n",
      "nan 339 0.1\n",
      "nan 340 0.1\n",
      "nan 341 0.1\n",
      "nan 342 0.1\n",
      "nan 343 0.1\n",
      "nan 344 0.1\n",
      "nan 345 0.1\n",
      "nan 346 0.1\n",
      "nan 347 0.1\n",
      "nan 348 0.1\n",
      "nan 349 0.1\n",
      "nan 350 0.1\n",
      "nan 351 0.1\n",
      "nan 352 0.1\n",
      "nan 353 0.1\n",
      "nan 354 0.1\n",
      "nan 355 0.1\n",
      "nan 356 0.1\n",
      "nan 357 0.1\n",
      "nan 358 0.1\n",
      "nan 359 0.1\n",
      "nan 360 0.1\n",
      "nan 361 0.1\n",
      "nan 362 0.1\n",
      "nan 363 0.1\n",
      "nan 364 0.1\n",
      "nan 365 0.1\n",
      "nan 366 0.1\n",
      "nan 367 0.1\n",
      "nan 368 0.1\n",
      "nan 369 0.1\n",
      "nan 370 0.1\n",
      "nan 371 0.1\n",
      "nan 372 0.1\n",
      "nan 373 0.1\n",
      "nan 374 0.1\n",
      "nan 375 0.1\n",
      "nan 376 0.1\n",
      "nan 377 0.1\n",
      "nan 378 0.1\n",
      "nan 379 0.1\n",
      "nan 380 0.1\n",
      "nan 381 0.1\n",
      "nan 382 0.1\n",
      "nan 383 0.1\n",
      "nan 384 0.1\n",
      "nan 385 0.1\n",
      "nan 386 0.1\n",
      "nan 387 0.1\n",
      "nan 388 0.1\n",
      "nan 389 0.1\n",
      "nan 390 0.1\n",
      "nan 391 0.1\n",
      "nan 392 0.1\n",
      "nan 393 0.1\n",
      "nan 394 0.1\n",
      "nan 395 0.1\n",
      "nan 396 0.1\n",
      "nan 397 0.1\n",
      "nan 398 0.1\n",
      "nan 399 0.1\n",
      "nan 400 0.1\n",
      "nan 401 0.1\n",
      "nan 402 0.1\n",
      "nan 403 0.1\n",
      "nan 404 0.1\n",
      "nan 405 0.1\n",
      "nan 406 0.1\n",
      "nan 407 0.1\n",
      "nan 408 0.1\n",
      "nan 409 0.1\n",
      "nan 410 0.1\n",
      "nan 411 0.1\n",
      "nan 412 0.1\n",
      "nan 413 0.1\n",
      "nan 414 0.1\n",
      "nan 415 0.1\n",
      "nan 416 0.1\n",
      "nan 417 0.1\n",
      "nan 418 0.1\n",
      "nan 419 0.1\n",
      "nan 420 0.1\n",
      "nan 421 0.1\n",
      "nan 422 0.1\n",
      "nan 423 0.1\n",
      "nan 424 0.1\n",
      "nan 425 0.1\n",
      "nan 426 0.1\n",
      "nan 427 0.1\n",
      "nan 428 0.1\n",
      "nan 429 0.1\n",
      "nan 430 0.1\n",
      "nan 431 0.1\n",
      "nan 432 0.1\n",
      "nan 433 0.1\n",
      "nan 434 0.1\n",
      "nan 435 0.1\n",
      "nan 436 0.1\n",
      "nan 437 0.1\n",
      "nan 438 0.1\n",
      "nan 439 0.1\n",
      "nan 440 0.1\n",
      "nan 441 0.1\n",
      "nan 442 0.1\n",
      "nan 443 0.1\n",
      "nan 444 0.1\n",
      "nan 445 0.1\n",
      "nan 446 0.1\n",
      "nan 447 0.1\n",
      "nan 448 0.1\n",
      "nan 449 0.1\n",
      "nan 450 0.1\n",
      "nan 451 0.1\n",
      "nan 452 0.1\n",
      "nan 453 0.1\n",
      "nan 454 0.1\n",
      "nan 455 0.1\n",
      "nan 456 0.1\n",
      "nan 457 0.1\n",
      "nan 458 0.1\n",
      "nan 459 0.1\n",
      "nan 460 0.1\n",
      "nan 461 0.1\n",
      "nan 462 0.1\n",
      "nan 463 0.1\n",
      "nan 464 0.1\n",
      "nan 465 0.1\n",
      "nan 466 0.1\n",
      "nan 467 0.1\n",
      "nan 468 0.1\n",
      "nan 469 0.1\n",
      "nan 470 0.1\n",
      "nan 471 0.1\n",
      "nan 472 0.1\n",
      "nan 473 0.1\n",
      "nan 474 0.1\n",
      "nan 475 0.1\n",
      "nan 476 0.1\n",
      "nan 477 0.1\n",
      "nan 478 0.1\n",
      "nan 479 0.1\n",
      "nan 480 0.1\n",
      "nan 481 0.1\n",
      "nan 482 0.1\n",
      "nan 483 0.1\n",
      "nan 484 0.1\n",
      "nan 485 0.1\n",
      "nan 486 0.1\n",
      "nan 487 0.1\n",
      "nan 488 0.1\n",
      "nan 489 0.1\n",
      "nan 490 0.1\n",
      "nan 491 0.1\n",
      "nan 492 0.1\n",
      "nan 493 0.1\n",
      "nan 494 0.1\n",
      "nan 495 0.1\n",
      "nan 496 0.1\n",
      "nan 497 0.1\n",
      "nan 498 0.1\n",
      "nan 499 0.1\n",
      "nan 500 0.1\n",
      "nan 501 0.1\n",
      "nan 502 0.1\n",
      "nan 503 0.1\n",
      "nan 504 0.1\n",
      "nan 505 0.1\n",
      "nan 506 0.1\n",
      "nan 507 0.1\n",
      "nan 508 0.1\n",
      "nan 509 0.1\n",
      "nan 510 0.1\n",
      "nan 511 0.1\n",
      "nan 512 0.1\n",
      "nan 513 0.1\n",
      "nan 514 0.1\n",
      "nan 515 0.1\n",
      "nan 516 0.1\n",
      "nan 517 0.1\n",
      "nan 518 0.1\n",
      "nan 519 0.1\n",
      "nan 520 0.1\n",
      "nan 521 0.1\n",
      "nan 522 0.1\n",
      "nan 523 0.1\n",
      "nan 524 0.1\n",
      "nan 525 0.1\n",
      "nan 526 0.1\n",
      "nan 527 0.1\n",
      "nan 528 0.1\n",
      "nan 529 0.1\n",
      "nan 530 0.1\n",
      "nan 531 0.1\n",
      "nan 532 0.1\n",
      "nan 533 0.1\n",
      "nan 534 0.1\n",
      "nan 535 0.1\n",
      "nan 536 0.1\n",
      "nan 537 0.1\n",
      "nan 538 0.1\n",
      "nan 539 0.1\n",
      "nan 540 0.1\n",
      "nan 541 0.1\n",
      "nan 542 0.1\n",
      "nan 543 0.1\n",
      "nan 544 0.1\n",
      "nan 545 0.1\n",
      "nan 546 0.1\n",
      "nan 547 0.1\n",
      "nan 548 0.1\n",
      "nan 549 0.1\n",
      "nan 550 0.1\n",
      "nan 551 0.1\n",
      "nan 552 0.1\n",
      "nan 553 0.1\n",
      "nan 554 0.1\n",
      "nan 555 0.1\n",
      "nan 556 0.1\n",
      "nan 557 0.1\n",
      "nan 558 0.1\n",
      "nan 559 0.1\n",
      "nan 560 0.1\n",
      "nan 561 0.1\n",
      "nan 562 0.1\n",
      "nan 563 0.1\n",
      "nan 564 0.1\n",
      "nan 565 0.1\n",
      "nan 566 0.1\n",
      "nan 567 0.1\n",
      "nan 568 0.1\n",
      "nan 569 0.1\n",
      "nan 570 0.1\n",
      "nan 571 0.1\n",
      "nan 572 0.1\n",
      "nan 573 0.1\n",
      "nan 574 0.1\n",
      "nan 575 0.1\n",
      "nan 576 0.1\n",
      "nan 577 0.1\n",
      "nan 578 0.1\n",
      "nan 579 0.1\n",
      "nan 580 0.1\n",
      "nan 581 0.1\n",
      "nan 582 0.1\n",
      "nan 583 0.1\n",
      "nan 584 0.1\n",
      "nan 585 0.1\n",
      "nan 586 0.1\n",
      "nan 587 0.1\n",
      "nan 588 0.1\n",
      "nan 589 0.1\n",
      "nan 590 0.1\n",
      "nan 591 0.1\n",
      "nan 592 0.1\n",
      "nan 593 0.1\n",
      "nan 594 0.1\n",
      "nan 595 0.1\n",
      "nan 596 0.1\n",
      "nan 597 0.1\n",
      "nan 598 0.1\n",
      "nan 599 0.1\n",
      "nan 600 0.1\n",
      "nan 601 0.1\n",
      "nan 602 0.1\n",
      "nan 603 0.1\n",
      "nan 604 0.1\n",
      "nan 605 0.1\n",
      "nan 606 0.1\n",
      "nan 607 0.1\n",
      "nan 608 0.1\n",
      "nan 609 0.1\n",
      "nan 610 0.1\n",
      "nan 611 0.1\n",
      "nan 612 0.1\n",
      "nan 613 0.1\n",
      "nan 614 0.1\n",
      "nan 615 0.1\n",
      "nan 616 0.1\n",
      "nan 617 0.1\n",
      "nan 618 0.1\n",
      "nan 619 0.1\n",
      "nan 620 0.1\n",
      "nan 621 0.1\n",
      "nan 622 0.1\n",
      "nan 623 0.1\n",
      "nan 624 0.1\n",
      "nan 625 0.1\n",
      "nan 626 0.1\n",
      "nan 627 0.1\n",
      "nan 628 0.1\n",
      "nan 629 0.1\n",
      "nan 630 0.1\n",
      "nan 631 0.1\n",
      "nan 632 0.1\n",
      "nan 633 0.1\n",
      "nan 634 0.1\n",
      "nan 635 0.1\n",
      "nan 636 0.1\n",
      "nan 637 0.1\n",
      "nan 638 0.1\n",
      "nan 639 0.1\n",
      "nan 640 0.1\n",
      "nan 641 0.1\n",
      "nan 642 0.1\n",
      "nan 643 0.1\n",
      "nan 644 0.1\n",
      "nan 645 0.1\n",
      "nan 646 0.1\n",
      "nan 647 0.1\n",
      "nan 648 0.1\n",
      "nan 649 0.1\n",
      "nan 650 0.1\n",
      "nan 651 0.1\n",
      "nan 652 0.1\n",
      "nan 653 0.1\n",
      "nan 654 0.1\n",
      "nan 655 0.1\n",
      "nan 656 0.1\n",
      "nan 657 0.1\n",
      "nan 658 0.1\n",
      "nan 659 0.1\n",
      "nan 660 0.1\n",
      "nan 661 0.1\n",
      "nan 662 0.1\n",
      "nan 663 0.1\n",
      "nan 664 0.1\n",
      "nan 665 0.1\n",
      "nan 666 0.1\n",
      "nan 667 0.1\n",
      "nan 668 0.1\n",
      "nan 669 0.1\n",
      "nan 670 0.1\n",
      "nan 671 0.1\n",
      "nan 672 0.1\n",
      "nan 673 0.1\n",
      "nan 674 0.1\n",
      "nan 675 0.1\n",
      "nan 676 0.1\n",
      "nan 677 0.1\n",
      "nan 678 0.1\n",
      "nan 679 0.1\n",
      "nan 680 0.1\n",
      "nan 681 0.1\n",
      "nan 682 0.1\n",
      "nan 683 0.1\n",
      "nan 684 0.1\n",
      "nan 685 0.1\n",
      "nan 686 0.1\n",
      "nan 687 0.1\n",
      "nan 688 0.1\n",
      "nan 689 0.1\n",
      "nan 690 0.1\n",
      "nan 691 0.1\n",
      "nan 692 0.1\n",
      "nan 693 0.1\n",
      "nan 694 0.1\n",
      "nan 695 0.1\n",
      "nan 696 0.1\n",
      "nan 697 0.1\n",
      "nan 698 0.1\n",
      "nan 699 0.1\n",
      "nan 700 0.1\n",
      "nan 701 0.1\n",
      "nan 702 0.1\n",
      "nan 703 0.1\n",
      "nan 704 0.1\n",
      "nan 705 0.1\n",
      "nan 706 0.1\n",
      "nan 707 0.1\n",
      "nan 708 0.1\n",
      "nan 709 0.1\n",
      "nan 710 0.1\n",
      "nan 711 0.1\n",
      "nan 712 0.1\n",
      "nan 713 0.1\n",
      "nan 714 0.1\n",
      "nan 715 0.1\n",
      "nan 716 0.1\n",
      "nan 717 0.1\n",
      "nan 718 0.1\n",
      "nan 719 0.1\n",
      "nan 720 0.1\n",
      "nan 721 0.1\n",
      "nan 722 0.1\n",
      "nan 723 0.1\n",
      "nan 724 0.1\n",
      "nan 725 0.1\n",
      "nan 726 0.1\n",
      "nan 727 0.1\n",
      "nan 728 0.1\n",
      "nan 729 0.1\n",
      "nan 730 0.1\n",
      "nan 731 0.1\n",
      "nan 732 0.1\n",
      "nan 733 0.1\n",
      "nan 734 0.1\n",
      "nan 735 0.1\n",
      "nan 736 0.1\n",
      "nan 737 0.1\n",
      "nan 738 0.1\n",
      "nan 739 0.1\n",
      "nan 740 0.1\n",
      "nan 741 0.1\n",
      "nan 742 0.1\n",
      "nan 743 0.1\n",
      "nan 744 0.1\n",
      "nan 745 0.1\n",
      "nan 746 0.1\n",
      "nan 747 0.1\n",
      "nan 748 0.1\n",
      "nan 749 0.1\n",
      "nan 750 0.1\n",
      "nan 751 0.1\n",
      "nan 752 0.1\n",
      "nan 753 0.1\n",
      "nan 754 0.1\n",
      "nan 755 0.1\n",
      "nan 756 0.1\n",
      "nan 757 0.1\n",
      "nan 758 0.1\n",
      "nan 759 0.1\n",
      "nan 760 0.1\n",
      "nan 761 0.1\n",
      "nan 762 0.1\n",
      "nan 763 0.1\n",
      "nan 764 0.1\n",
      "nan 765 0.1\n",
      "nan 766 0.1\n",
      "nan 767 0.1\n",
      "nan 768 0.1\n",
      "nan 769 0.1\n",
      "nan 770 0.1\n",
      "nan 771 0.1\n",
      "nan 772 0.1\n",
      "nan 773 0.1\n",
      "nan 774 0.1\n",
      "nan 775 0.1\n",
      "nan 776 0.1\n",
      "nan 777 0.1\n",
      "nan 778 0.1\n",
      "nan 779 0.1\n",
      "nan 780 0.1\n",
      "nan 781 0.1\n",
      "nan 782 0.1\n",
      "nan 783 0.1\n",
      "nan 784 0.1\n",
      "nan 785 0.1\n",
      "nan 786 0.1\n",
      "nan 787 0.1\n",
      "nan 788 0.1\n",
      "nan 789 0.1\n",
      "nan 790 0.1\n",
      "nan 791 0.1\n",
      "nan 792 0.1\n",
      "nan 793 0.1\n",
      "nan 794 0.1\n",
      "nan 795 0.1\n",
      "nan 796 0.1\n",
      "nan 797 0.1\n",
      "nan 798 0.1\n",
      "nan 799 0.1\n",
      "nan 800 0.1\n",
      "nan 801 0.1\n",
      "nan 802 0.1\n",
      "nan 803 0.1\n",
      "nan 804 0.1\n",
      "nan 805 0.1\n",
      "nan 806 0.1\n",
      "nan 807 0.1\n",
      "nan 808 0.1\n",
      "nan 809 0.1\n",
      "nan 810 0.1\n",
      "nan 811 0.1\n",
      "nan 812 0.1\n",
      "nan 813 0.1\n",
      "nan 814 0.1\n",
      "nan 815 0.1\n",
      "nan 816 0.1\n",
      "nan 817 0.1\n",
      "nan 818 0.1\n",
      "nan 819 0.1\n",
      "nan 820 0.1\n",
      "nan 821 0.1\n",
      "nan 822 0.1\n",
      "nan 823 0.1\n",
      "nan 824 0.1\n",
      "nan 825 0.1\n",
      "nan 826 0.1\n",
      "nan 827 0.1\n",
      "nan 828 0.1\n",
      "nan 829 0.1\n",
      "nan 830 0.1\n",
      "nan 831 0.1\n",
      "nan 832 0.1\n",
      "nan 833 0.1\n",
      "nan 834 0.1\n",
      "nan 835 0.1\n",
      "nan 836 0.1\n",
      "nan 837 0.1\n",
      "nan 838 0.1\n",
      "nan 839 0.1\n",
      "nan 840 0.1\n",
      "nan 841 0.1\n",
      "nan 842 0.1\n",
      "nan 843 0.1\n",
      "nan 844 0.1\n",
      "nan 845 0.1\n",
      "nan 846 0.1\n",
      "nan 847 0.1\n",
      "nan 848 0.1\n",
      "nan 849 0.1\n",
      "nan 850 0.1\n",
      "nan 851 0.1\n",
      "nan 852 0.1\n",
      "nan 853 0.1\n",
      "nan 854 0.1\n",
      "nan 855 0.1\n",
      "nan 856 0.1\n",
      "nan 857 0.1\n",
      "nan 858 0.1\n",
      "nan 859 0.1\n",
      "nan 860 0.1\n",
      "nan 861 0.1\n",
      "nan 862 0.1\n",
      "nan 863 0.1\n",
      "nan 864 0.1\n",
      "nan 865 0.1\n",
      "nan 866 0.1\n",
      "nan 867 0.1\n",
      "nan 868 0.1\n",
      "nan 869 0.1\n",
      "nan 870 0.1\n",
      "nan 871 0.1\n",
      "nan 872 0.1\n",
      "nan 873 0.1\n",
      "nan 874 0.1\n",
      "nan 875 0.1\n",
      "nan 876 0.1\n",
      "nan 877 0.1\n",
      "nan 878 0.1\n",
      "nan 879 0.1\n",
      "nan 880 0.1\n",
      "nan 881 0.1\n",
      "nan 882 0.1\n",
      "nan 883 0.1\n",
      "nan 884 0.1\n",
      "nan 885 0.1\n",
      "nan 886 0.1\n",
      "nan 887 0.1\n",
      "nan 888 0.1\n",
      "nan 889 0.1\n",
      "nan 890 0.1\n",
      "nan 891 0.1\n",
      "nan 892 0.1\n",
      "nan 893 0.1\n",
      "nan 894 0.1\n",
      "nan 895 0.1\n",
      "nan 896 0.1\n",
      "nan 897 0.1\n",
      "nan 898 0.1\n",
      "nan 899 0.1\n",
      "nan 900 0.1\n",
      "nan 901 0.1\n",
      "nan 902 0.1\n",
      "nan 903 0.1\n",
      "nan 904 0.1\n",
      "nan 905 0.1\n",
      "nan 906 0.1\n",
      "nan 907 0.1\n",
      "nan 908 0.1\n",
      "nan 909 0.1\n",
      "nan 910 0.1\n",
      "nan 911 0.1\n",
      "nan 912 0.1\n",
      "nan 913 0.1\n",
      "nan 914 0.1\n",
      "nan 915 0.1\n",
      "nan 916 0.1\n",
      "nan 917 0.1\n",
      "nan 918 0.1\n",
      "nan 919 0.1\n",
      "nan 920 0.1\n",
      "nan 921 0.1\n",
      "nan 922 0.1\n",
      "nan 923 0.1\n",
      "nan 924 0.1\n",
      "nan 925 0.1\n",
      "nan 926 0.1\n",
      "nan 927 0.1\n",
      "nan 928 0.1\n",
      "nan 929 0.1\n",
      "nan 930 0.1\n",
      "nan 931 0.1\n",
      "nan 932 0.1\n",
      "nan 933 0.1\n",
      "nan 934 0.1\n",
      "nan 935 0.1\n",
      "nan 936 0.1\n",
      "nan 937 0.1\n",
      "nan 938 0.1\n",
      "nan 939 0.1\n",
      "nan 940 0.1\n",
      "nan 941 0.1\n",
      "nan 942 0.1\n",
      "nan 943 0.1\n",
      "nan 944 0.1\n",
      "nan 945 0.1\n",
      "nan 946 0.1\n",
      "nan 947 0.1\n",
      "nan 948 0.1\n",
      "nan 949 0.1\n",
      "nan 950 0.1\n",
      "nan 951 0.1\n",
      "nan 952 0.1\n",
      "nan 953 0.1\n",
      "nan 954 0.1\n",
      "nan 955 0.1\n",
      "nan 956 0.1\n",
      "nan 957 0.1\n",
      "nan 958 0.1\n",
      "nan 959 0.1\n",
      "nan 960 0.1\n",
      "nan 961 0.1\n",
      "nan 962 0.1\n",
      "nan 963 0.1\n",
      "nan 964 0.1\n",
      "nan 965 0.1\n",
      "nan 966 0.1\n",
      "nan 967 0.1\n",
      "nan 968 0.1\n",
      "nan 969 0.1\n",
      "nan 970 0.1\n",
      "nan 971 0.1\n",
      "nan 972 0.1\n",
      "nan 973 0.1\n",
      "nan 974 0.1\n",
      "nan 975 0.1\n",
      "nan 976 0.1\n",
      "nan 977 0.1\n",
      "nan 978 0.1\n",
      "nan 979 0.1\n",
      "nan 980 0.1\n",
      "nan 981 0.1\n",
      "nan 982 0.1\n",
      "nan 983 0.1\n",
      "nan 984 0.1\n",
      "nan 985 0.1\n",
      "nan 986 0.1\n",
      "nan 987 0.1\n",
      "nan 988 0.1\n",
      "nan 989 0.1\n",
      "nan 990 0.1\n",
      "nan 991 0.1\n",
      "nan 992 0.1\n",
      "nan 993 0.1\n",
      "nan 994 0.1\n",
      "nan 995 0.1\n",
      "nan 996 0.1\n",
      "nan 997 0.1\n",
      "nan 998 0.1\n",
      "nan 999 0.1\n",
      "nan 1000 0.1\n",
      "nan 1001 0.1\n",
      "nan 1002 0.1\n",
      "nan 1003 0.1\n",
      "nan 1004 0.1\n",
      "nan 1005 0.1\n",
      "nan 1006 0.1\n",
      "nan 1007 0.1\n",
      "nan 1008 0.1\n",
      "nan 1009 0.1\n",
      "nan 1010 0.1\n",
      "nan 1011 0.1\n",
      "nan 1012 0.1\n",
      "nan 1013 0.1\n",
      "nan 1014 0.1\n",
      "nan 1015 0.1\n",
      "nan 1016 0.1\n",
      "nan 1017 0.1\n",
      "nan 1018 0.1\n",
      "nan 1019 0.1\n",
      "nan 1020 0.1\n",
      "nan 1021 0.1\n",
      "nan 1022 0.1\n",
      "nan 1023 0.1\n",
      "nan 1024 0.1\n",
      "nan 1025 0.1\n",
      "nan 1026 0.1\n",
      "nan 1027 0.1\n",
      "nan 1028 0.1\n",
      "nan 1029 0.1\n",
      "nan 1030 0.1\n",
      "nan 1031 0.1\n",
      "nan 1032 0.1\n",
      "nan 1033 0.1\n",
      "nan 1034 0.1\n",
      "nan 1035 0.1\n",
      "nan 1036 0.1\n",
      "nan 1037 0.1\n",
      "nan 1038 0.1\n",
      "nan 1039 0.1\n",
      "nan 1040 0.1\n",
      "nan 1041 0.1\n",
      "nan 1042 0.1\n",
      "nan 1043 0.1\n",
      "nan 1044 0.1\n",
      "nan 1045 0.1\n",
      "nan 1046 0.1\n",
      "nan 1047 0.1\n",
      "nan 1048 0.1\n",
      "nan 1049 0.1\n",
      "nan 1050 0.1\n",
      "nan 1051 0.1\n",
      "nan 1052 0.1\n",
      "nan 1053 0.1\n",
      "nan 1054 0.1\n",
      "nan 1055 0.1\n",
      "nan 1056 0.1\n",
      "nan 1057 0.1\n",
      "nan 1058 0.1\n",
      "nan 1059 0.1\n",
      "nan 1060 0.1\n",
      "nan 1061 0.1\n",
      "nan 1062 0.1\n",
      "nan 1063 0.1\n",
      "nan 1064 0.1\n",
      "nan 1065 0.1\n",
      "nan 1066 0.1\n",
      "nan 1067 0.1\n",
      "nan 1068 0.1\n",
      "nan 1069 0.1\n",
      "nan 1070 0.1\n",
      "nan 1071 0.1\n",
      "nan 1072 0.1\n",
      "nan 1073 0.1\n",
      "nan 1074 0.1\n",
      "nan 1075 0.1\n",
      "nan 1076 0.1\n",
      "nan 1077 0.1\n",
      "nan 1078 0.1\n",
      "nan 1079 0.1\n",
      "nan 1080 0.1\n",
      "nan 1081 0.1\n",
      "nan 1082 0.1\n",
      "nan 1083 0.1\n",
      "nan 1084 0.1\n",
      "nan 1085 0.1\n",
      "nan 1086 0.1\n",
      "nan 1087 0.1\n",
      "nan 1088 0.1\n",
      "nan 1089 0.1\n",
      "nan 1090 0.1\n",
      "nan 1091 0.1\n",
      "nan 1092 0.1\n",
      "nan 1093 0.1\n",
      "nan 1094 0.1\n",
      "nan 1095 0.1\n",
      "nan 1096 0.1\n",
      "nan 1097 0.1\n",
      "nan 1098 0.1\n",
      "nan 1099 0.1\n",
      "nan 1100 0.1\n",
      "nan 1101 0.1\n",
      "nan 1102 0.1\n",
      "nan 1103 0.1\n",
      "nan 1104 0.1\n",
      "nan 1105 0.1\n",
      "nan 1106 0.1\n",
      "nan 1107 0.1\n",
      "nan 1108 0.1\n",
      "nan 1109 0.1\n",
      "nan 1110 0.1\n",
      "nan 1111 0.1\n",
      "nan 1112 0.1\n",
      "nan 1113 0.1\n",
      "nan 1114 0.1\n",
      "nan 1115 0.1\n",
      "nan 1116 0.1\n",
      "nan 1117 0.1\n",
      "nan 1118 0.1\n",
      "nan 1119 0.1\n",
      "nan 1120 0.1\n",
      "nan 1121 0.1\n",
      "nan 1122 0.1\n",
      "nan 1123 0.1\n",
      "nan 1124 0.1\n",
      "nan 1125 0.1\n",
      "nan 1126 0.1\n",
      "nan 1127 0.1\n",
      "nan 1128 0.1\n",
      "nan 1129 0.1\n",
      "nan 1130 0.1\n",
      "nan 1131 0.1\n",
      "nan 1132 0.1\n",
      "nan 1133 0.1\n",
      "nan 1134 0.1\n",
      "nan 1135 0.1\n",
      "nan 1136 0.1\n",
      "nan 1137 0.1\n",
      "nan 1138 0.1\n",
      "nan 1139 0.1\n",
      "nan 1140 0.1\n",
      "nan 1141 0.1\n",
      "nan 1142 0.1\n",
      "nan 1143 0.1\n",
      "nan 1144 0.1\n",
      "nan 1145 0.1\n",
      "nan 1146 0.1\n",
      "nan 1147 0.1\n",
      "nan 1148 0.1\n",
      "nan 1149 0.1\n",
      "nan 1150 0.1\n",
      "nan 1151 0.1\n",
      "nan 1152 0.1\n",
      "nan 1153 0.1\n",
      "nan 1154 0.1\n",
      "nan 1155 0.1\n",
      "nan 1156 0.1\n",
      "nan 1157 0.1\n",
      "nan 1158 0.1\n",
      "nan 1159 0.1\n",
      "nan 1160 0.1\n",
      "nan 1161 0.1\n",
      "nan 1162 0.1\n",
      "nan 1163 0.1\n",
      "nan 1164 0.1\n",
      "nan 1165 0.1\n",
      "nan 1166 0.1\n",
      "nan 1167 0.1\n",
      "nan 1168 0.1\n",
      "nan 1169 0.1\n",
      "nan 1170 0.1\n",
      "nan 1171 0.1\n",
      "nan 1172 0.1\n",
      "nan 1173 0.1\n",
      "nan 1174 0.1\n",
      "nan 1175 0.1\n",
      "nan 1176 0.1\n",
      "nan 1177 0.1\n",
      "nan 1178 0.1\n",
      "nan 1179 0.1\n",
      "nan 1180 0.1\n",
      "nan 1181 0.1\n",
      "nan 1182 0.1\n",
      "nan 1183 0.1\n",
      "nan 1184 0.1\n",
      "nan 1185 0.1\n",
      "nan 1186 0.1\n",
      "nan 1187 0.1\n",
      "nan 1188 0.1\n",
      "nan 1189 0.1\n",
      "nan 1190 0.1\n",
      "nan 1191 0.1\n",
      "nan 1192 0.1\n",
      "nan 1193 0.1\n",
      "nan 1194 0.1\n",
      "nan 1195 0.1\n",
      "nan 1196 0.1\n",
      "nan 1197 0.1\n",
      "nan 1198 0.1\n",
      "nan 1199 0.1\n",
      "nan 1200 0.1\n",
      "nan 1201 0.1\n",
      "nan 1202 0.1\n",
      "nan 1203 0.1\n",
      "nan 1204 0.1\n",
      "nan 1205 0.1\n",
      "nan 1206 0.1\n",
      "nan 1207 0.1\n",
      "nan 1208 0.1\n",
      "nan 1209 0.1\n",
      "nan 1210 0.1\n",
      "nan 1211 0.1\n",
      "nan 1212 0.1\n",
      "nan 1213 0.1\n",
      "nan 1214 0.1\n",
      "nan 1215 0.1\n",
      "nan 1216 0.1\n",
      "nan 1217 0.1\n",
      "nan 1218 0.1\n",
      "nan 1219 0.1\n",
      "nan 1220 0.1\n",
      "nan 1221 0.1\n",
      "nan 1222 0.1\n",
      "nan 1223 0.1\n",
      "nan 1224 0.1\n",
      "nan 1225 0.1\n",
      "nan 1226 0.1\n",
      "nan 1227 0.1\n",
      "nan 1228 0.1\n",
      "nan 1229 0.1\n",
      "nan 1230 0.1\n",
      "nan 1231 0.1\n",
      "nan 1232 0.1\n",
      "nan 1233 0.1\n",
      "nan 1234 0.1\n",
      "nan 1235 0.1\n",
      "nan 1236 0.1\n",
      "nan 1237 0.1\n",
      "nan 1238 0.1\n",
      "nan 1239 0.1\n",
      "nan 1240 0.1\n",
      "nan 1241 0.1\n",
      "nan 1242 0.1\n",
      "nan 1243 0.1\n",
      "nan 1244 0.1\n",
      "nan 1245 0.1\n",
      "nan 1246 0.1\n",
      "nan 1247 0.1\n",
      "nan 1248 0.1\n",
      "nan 1249 0.1\n",
      "nan 1250 0.1\n",
      "nan 1251 0.1\n",
      "nan 1252 0.1\n",
      "nan 1253 0.1\n",
      "nan 1254 0.1\n",
      "nan 1255 0.1\n",
      "nan 1256 0.1\n",
      "nan 1257 0.1\n",
      "nan 1258 0.1\n",
      "nan 1259 0.1\n",
      "nan 1260 0.1\n",
      "nan 1261 0.1\n",
      "nan 1262 0.1\n",
      "nan 1263 0.1\n",
      "nan 1264 0.1\n",
      "nan 1265 0.1\n",
      "nan 1266 0.1\n",
      "nan 1267 0.1\n",
      "nan 1268 0.1\n",
      "nan 1269 0.1\n",
      "nan 1270 0.1\n",
      "nan 1271 0.1\n",
      "nan 1272 0.1\n",
      "nan 1273 0.1\n",
      "nan 1274 0.1\n",
      "nan 1275 0.1\n",
      "nan 1276 0.1\n",
      "nan 1277 0.1\n",
      "nan 1278 0.1\n",
      "nan 1279 0.1\n",
      "nan 1280 0.1\n",
      "nan 1281 0.1\n",
      "nan 1282 0.1\n",
      "nan 1283 0.1\n",
      "nan 1284 0.1\n",
      "nan 1285 0.1\n",
      "nan 1286 0.1\n",
      "nan 1287 0.1\n",
      "nan 1288 0.1\n",
      "nan 1289 0.1\n",
      "nan 1290 0.1\n",
      "nan 1291 0.1\n",
      "nan 1292 0.1\n",
      "nan 1293 0.1\n",
      "nan 1294 0.1\n",
      "nan 1295 0.1\n",
      "nan 1296 0.1\n",
      "nan 1297 0.1\n",
      "nan 1298 0.1\n",
      "nan 1299 0.1\n",
      "nan 1300 0.1\n",
      "nan 1301 0.1\n",
      "nan 1302 0.1\n",
      "nan 1303 0.1\n",
      "nan 1304 0.1\n",
      "nan 1305 0.1\n",
      "nan 1306 0.1\n",
      "nan 1307 0.1\n",
      "nan 1308 0.1\n",
      "nan 1309 0.1\n",
      "nan 1310 0.1\n",
      "nan 1311 0.1\n",
      "nan 1312 0.1\n",
      "nan 1313 0.1\n",
      "nan 1314 0.1\n",
      "nan 1315 0.1\n",
      "nan 1316 0.1\n",
      "nan 1317 0.1\n",
      "nan 1318 0.1\n",
      "nan 1319 0.1\n",
      "nan 1320 0.1\n",
      "nan 1321 0.1\n",
      "nan 1322 0.1\n",
      "nan 1323 0.1\n",
      "nan 1324 0.1\n",
      "nan 1325 0.1\n",
      "nan 1326 0.1\n",
      "nan 1327 0.1\n",
      "nan 1328 0.1\n",
      "nan 1329 0.1\n",
      "nan 1330 0.1\n",
      "nan 1331 0.1\n",
      "nan 1332 0.1\n",
      "nan 1333 0.1\n",
      "nan 1334 0.1\n",
      "nan 1335 0.1\n",
      "nan 1336 0.1\n",
      "nan 1337 0.1\n",
      "nan 1338 0.1\n",
      "nan 1339 0.1\n",
      "nan 1340 0.1\n",
      "nan 1341 0.1\n",
      "nan 1342 0.1\n",
      "nan 1343 0.1\n",
      "nan 1344 0.1\n",
      "nan 1345 0.1\n",
      "nan 1346 0.1\n",
      "nan 1347 0.1\n",
      "nan 1348 0.1\n",
      "nan 1349 0.1\n",
      "nan 1350 0.1\n",
      "nan 1351 0.1\n",
      "nan 1352 0.1\n",
      "nan 1353 0.1\n",
      "nan 1354 0.1\n",
      "nan 1355 0.1\n",
      "nan 1356 0.1\n",
      "nan 1357 0.1\n",
      "nan 1358 0.1\n",
      "nan 1359 0.1\n",
      "nan 1360 0.1\n",
      "nan 1361 0.1\n",
      "nan 1362 0.1\n",
      "nan 1363 0.1\n",
      "nan 1364 0.1\n",
      "nan 1365 0.1\n",
      "nan 1366 0.1\n",
      "nan 1367 0.1\n",
      "nan 1368 0.1\n",
      "nan 1369 0.1\n",
      "nan 1370 0.1\n",
      "nan 1371 0.1\n",
      "nan 1372 0.1\n",
      "nan 1373 0.1\n",
      "nan 1374 0.1\n",
      "nan 1375 0.1\n",
      "nan 1376 0.1\n",
      "nan 1377 0.1\n",
      "nan 1378 0.1\n",
      "nan 1379 0.1\n",
      "nan 1380 0.1\n",
      "nan 1381 0.1\n",
      "nan 1382 0.1\n",
      "nan 1383 0.1\n",
      "nan 1384 0.1\n",
      "nan 1385 0.1\n",
      "nan 1386 0.1\n",
      "nan 1387 0.1\n",
      "nan 1388 0.1\n",
      "nan 1389 0.1\n",
      "nan 1390 0.1\n",
      "nan 1391 0.1\n",
      "nan 1392 0.1\n",
      "nan 1393 0.1\n",
      "nan 1394 0.1\n",
      "nan 1395 0.1\n",
      "nan 1396 0.1\n",
      "nan 1397 0.1\n",
      "nan 1398 0.1\n",
      "nan 1399 0.1\n",
      "nan 1400 0.1\n",
      "nan 1401 0.1\n",
      "nan 1402 0.1\n",
      "nan 1403 0.1\n",
      "nan 1404 0.1\n",
      "nan 1405 0.1\n",
      "nan 1406 0.1\n",
      "nan 1407 0.1\n",
      "nan 1408 0.1\n",
      "nan 1409 0.1\n",
      "nan 1410 0.1\n",
      "nan 1411 0.1\n",
      "nan 1412 0.1\n",
      "nan 1413 0.1\n",
      "nan 1414 0.1\n",
      "nan 1415 0.1\n",
      "nan 1416 0.1\n",
      "nan 1417 0.1\n",
      "nan 1418 0.1\n",
      "nan 1419 0.1\n",
      "nan 1420 0.1\n",
      "nan 1421 0.1\n",
      "nan 1422 0.1\n",
      "nan 1423 0.1\n",
      "nan 1424 0.1\n",
      "nan 1425 0.1\n",
      "nan 1426 0.1\n",
      "nan 1427 0.1\n",
      "nan 1428 0.1\n",
      "nan 1429 0.1\n",
      "nan 1430 0.1\n",
      "nan 1431 0.1\n",
      "nan 1432 0.1\n",
      "nan 1433 0.1\n",
      "nan 1434 0.1\n",
      "nan 1435 0.1\n",
      "nan 1436 0.1\n",
      "nan 1437 0.1\n",
      "nan 1438 0.1\n",
      "nan 1439 0.1\n",
      "nan 1440 0.1\n",
      "nan 1441 0.1\n",
      "nan 1442 0.1\n",
      "nan 1443 0.1\n",
      "nan 1444 0.1\n",
      "nan 1445 0.1\n",
      "nan 1446 0.1\n",
      "nan 1447 0.1\n",
      "nan 1448 0.1\n",
      "nan 1449 0.1\n",
      "nan 1450 0.1\n",
      "nan 1451 0.1\n",
      "nan 1452 0.1\n",
      "nan 1453 0.1\n",
      "nan 1454 0.1\n",
      "nan 1455 0.1\n",
      "nan 1456 0.1\n",
      "nan 1457 0.1\n",
      "nan 1458 0.1\n",
      "nan 1459 0.1\n",
      "nan 1460 0.1\n",
      "nan 1461 0.1\n",
      "nan 1462 0.1\n",
      "nan 1463 0.1\n",
      "nan 1464 0.1\n",
      "nan 1465 0.1\n",
      "nan 1466 0.1\n",
      "nan 1467 0.1\n",
      "nan 1468 0.1\n",
      "nan 1469 0.1\n",
      "nan 1470 0.1\n",
      "nan 1471 0.1\n",
      "nan 1472 0.1\n",
      "nan 1473 0.1\n",
      "nan 1474 0.1\n",
      "nan 1475 0.1\n",
      "nan 1476 0.1\n",
      "nan 1477 0.1\n",
      "nan 1478 0.1\n",
      "nan 1479 0.1\n",
      "nan 1480 0.1\n",
      "nan 1481 0.1\n",
      "nan 1482 0.1\n",
      "nan 1483 0.1\n",
      "nan 1484 0.1\n",
      "nan 1485 0.1\n",
      "nan 1486 0.1\n",
      "nan 1487 0.1\n",
      "nan 1488 0.1\n",
      "nan 1489 0.1\n",
      "nan 1490 0.1\n",
      "nan 1491 0.1\n",
      "nan 1492 0.1\n",
      "nan 1493 0.1\n",
      "nan 1494 0.1\n",
      "nan 1495 0.1\n",
      "nan 1496 0.1\n",
      "nan 1497 0.1\n",
      "nan 1498 0.1\n",
      "nan 1499 0.1\n",
      "nan 1500 0.1\n",
      "nan 1501 0.1\n",
      "nan 1502 0.1\n",
      "nan 1503 0.1\n",
      "nan 1504 0.1\n",
      "nan 1505 0.1\n",
      "nan 1506 0.1\n",
      "nan 1507 0.1\n",
      "nan 1508 0.1\n",
      "nan 1509 0.1\n",
      "nan 1510 0.1\n",
      "nan 1511 0.1\n",
      "nan 1512 0.1\n",
      "nan 1513 0.1\n",
      "nan 1514 0.1\n",
      "nan 1515 0.1\n",
      "nan 1516 0.1\n",
      "nan 1517 0.1\n",
      "nan 1518 0.1\n",
      "nan 1519 0.1\n",
      "nan 1520 0.1\n",
      "nan 1521 0.1\n",
      "nan 1522 0.1\n",
      "nan 1523 0.1\n",
      "nan 1524 0.1\n",
      "nan 1525 0.1\n",
      "nan 1526 0.1\n",
      "nan 1527 0.1\n",
      "nan 1528 0.1\n",
      "nan 1529 0.1\n",
      "nan 1530 0.1\n",
      "nan 1531 0.1\n",
      "nan 1532 0.1\n",
      "nan 1533 0.1\n",
      "nan 1534 0.1\n",
      "nan 1535 0.1\n",
      "nan 1536 0.1\n",
      "nan 1537 0.1\n",
      "nan 1538 0.1\n",
      "nan 1539 0.1\n",
      "nan 1540 0.1\n",
      "nan 1541 0.1\n",
      "nan 1542 0.1\n",
      "nan 1543 0.1\n",
      "nan 1544 0.1\n",
      "nan 1545 0.1\n",
      "nan 1546 0.1\n",
      "nan 1547 0.1\n",
      "nan 1548 0.1\n",
      "nan 1549 0.1\n",
      "nan 1550 0.1\n",
      "nan 1551 0.1\n",
      "nan 1552 0.1\n",
      "nan 1553 0.1\n",
      "nan 1554 0.1\n",
      "nan 1555 0.1\n",
      "nan 1556 0.1\n",
      "nan 1557 0.1\n",
      "nan 1558 0.1\n",
      "nan 1559 0.1\n",
      "nan 1560 0.1\n",
      "nan 1561 0.1\n",
      "nan 1562 0.1\n",
      "nan 1563 0.1\n",
      "nan 1564 0.1\n",
      "nan 1565 0.1\n",
      "nan 1566 0.1\n",
      "nan 1567 0.1\n",
      "nan 1568 0.1\n",
      "nan 1569 0.1\n",
      "nan 1570 0.1\n",
      "nan 1571 0.1\n",
      "nan 1572 0.1\n",
      "nan 1573 0.1\n",
      "nan 1574 0.1\n",
      "nan 1575 0.1\n",
      "nan 1576 0.1\n",
      "nan 1577 0.1\n",
      "nan 1578 0.1\n",
      "nan 1579 0.1\n",
      "nan 1580 0.1\n",
      "nan 1581 0.1\n",
      "nan 1582 0.1\n",
      "nan 1583 0.1\n",
      "nan 1584 0.1\n",
      "nan 1585 0.1\n",
      "nan 1586 0.1\n",
      "nan 1587 0.1\n",
      "nan 1588 0.1\n",
      "nan 1589 0.1\n",
      "nan 1590 0.1\n",
      "nan 1591 0.1\n",
      "nan 1592 0.1\n",
      "nan 1593 0.1\n",
      "nan 1594 0.1\n",
      "nan 1595 0.1\n",
      "nan 1596 0.1\n",
      "nan 1597 0.1\n",
      "nan 1598 0.1\n",
      "nan 1599 0.1\n",
      "nan 1600 0.1\n",
      "nan 1601 0.1\n",
      "nan 1602 0.1\n",
      "nan 1603 0.1\n",
      "nan 1604 0.1\n",
      "nan 1605 0.1\n",
      "nan 1606 0.1\n",
      "nan 1607 0.1\n",
      "nan 1608 0.1\n",
      "nan 1609 0.1\n",
      "nan 1610 0.1\n",
      "nan 1611 0.1\n",
      "nan 1612 0.1\n",
      "nan 1613 0.1\n",
      "nan 1614 0.1\n",
      "nan 1615 0.1\n",
      "nan 1616 0.1\n",
      "nan 1617 0.1\n",
      "nan 1618 0.1\n",
      "nan 1619 0.1\n",
      "nan 1620 0.1\n",
      "nan 1621 0.1\n",
      "nan 1622 0.1\n",
      "nan 1623 0.1\n",
      "nan 1624 0.1\n",
      "nan 1625 0.1\n",
      "nan 1626 0.1\n",
      "nan 1627 0.1\n",
      "nan 1628 0.1\n",
      "nan 1629 0.1\n",
      "nan 1630 0.1\n",
      "nan 1631 0.1\n",
      "nan 1632 0.1\n",
      "nan 1633 0.1\n",
      "nan 1634 0.1\n",
      "nan 1635 0.1\n",
      "nan 1636 0.1\n",
      "nan 1637 0.1\n",
      "nan 1638 0.1\n",
      "nan 1639 0.1\n",
      "nan 1640 0.1\n",
      "nan 1641 0.1\n",
      "nan 1642 0.1\n",
      "nan 1643 0.1\n",
      "nan 1644 0.1\n",
      "nan 1645 0.1\n",
      "nan 1646 0.1\n",
      "nan 1647 0.1\n",
      "nan 1648 0.1\n",
      "nan 1649 0.1\n",
      "nan 1650 0.1\n",
      "nan 1651 0.1\n",
      "nan 1652 0.1\n",
      "nan 1653 0.1\n",
      "nan 1654 0.1\n",
      "nan 1655 0.1\n",
      "nan 1656 0.1\n",
      "nan 1657 0.1\n",
      "nan 1658 0.1\n",
      "nan 1659 0.1\n",
      "nan 1660 0.1\n",
      "nan 1661 0.1\n",
      "nan 1662 0.1\n",
      "nan 1663 0.1\n",
      "nan 1664 0.1\n",
      "nan 1665 0.1\n",
      "nan 1666 0.1\n",
      "nan 1667 0.1\n",
      "nan 1668 0.1\n",
      "nan 1669 0.1\n",
      "nan 1670 0.1\n",
      "nan 1671 0.1\n",
      "nan 1672 0.1\n",
      "nan 1673 0.1\n",
      "nan 1674 0.1\n",
      "nan 1675 0.1\n",
      "nan 1676 0.1\n",
      "nan 1677 0.1\n",
      "nan 1678 0.1\n",
      "nan 1679 0.1\n",
      "nan 1680 0.1\n",
      "nan 1681 0.1\n",
      "nan 1682 0.1\n",
      "nan 1683 0.1\n",
      "nan 1684 0.1\n",
      "nan 1685 0.1\n",
      "nan 1686 0.1\n",
      "nan 1687 0.1\n",
      "nan 1688 0.1\n",
      "nan 1689 0.1\n",
      "nan 1690 0.1\n",
      "nan 1691 0.1\n",
      "nan 1692 0.1\n",
      "nan 1693 0.1\n",
      "nan 1694 0.1\n",
      "nan 1695 0.1\n",
      "nan 1696 0.1\n",
      "nan 1697 0.1\n",
      "nan 1698 0.1\n",
      "nan 1699 0.1\n",
      "nan 1700 0.1\n",
      "nan 1701 0.1\n",
      "nan 1702 0.1\n",
      "nan 1703 0.1\n",
      "nan 1704 0.1\n",
      "nan 1705 0.1\n",
      "nan 1706 0.1\n",
      "nan 1707 0.1\n",
      "nan 1708 0.1\n",
      "nan 1709 0.1\n",
      "nan 1710 0.1\n",
      "nan 1711 0.1\n",
      "nan 1712 0.1\n",
      "nan 1713 0.1\n",
      "nan 1714 0.1\n",
      "nan 1715 0.1\n",
      "nan 1716 0.1\n",
      "nan 1717 0.1\n",
      "nan 1718 0.1\n",
      "nan 1719 0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device_and_dtype_specifications = dict(dtype=torch.float64, device=torch.device(\"cpu\"))\n",
    "epsilon = 0.1\n",
    "num_epochs = 5000\n",
    "\n",
    "phi_network.to(**device_and_dtype_specifications)\n",
    "psi_network.to(**device_and_dtype_specifications)\n",
    "\n",
    "phi_network_optimizer = torch.optim.Adam([dict(params=phi_network.parameters())], lr=0.1)\n",
    "psi_network_optimizer = torch.optim.Adam([dict(params=psi_network.parameters())], lr=0.1)\n",
    "\n",
    "X, Y = create_joint_x_y(num_points_to_generate)\n",
    "X_tensor = torch.tensor(X, **device_and_dtype_specifications)\n",
    "Y_tensor = torch.tensor(Y, **device_and_dtype_specifications)\n",
    "# U_tensor = torch_sphere_uniform(num_points_to_generate, Y.shape[1], **device_and_dtype_specifications)\n",
    "dataset_size = num_points_to_generate\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "def estimate_entropy_dual(X_tensor, Y_tensor, U_tensor, phi_net, psi_net, k=5, epsilon=0.1, use_log=True):\n",
    "        \"\"\"\n",
    "        Estimate the dual objective term for entropy estimation.\n",
    "\n",
    "        This function implements the core calculation based on nearest neighbors and learned\n",
    "        potential functions phi and psi. It offers an option to oversample some x's to better approximate P(Y|X)\n",
    "\n",
    "        Args:\n",
    "        X_tensor (torch.Tensor): The input tensor for x, with shape [n, p].\n",
    "        Y_tensor (torch.Tensor): The input tensor for y, with shape [n, q].\n",
    "        U_tensor (torch.Tensor): The tensor of oversampled variables u, with shape [m, q].\n",
    "        phi_net (nn.Module): The neural network representing the potential function phi(u, x).\n",
    "        psi_net (nn.Module): The neural network representing the potential function psi(x, y).\n",
    "        k (int, optional): The number of nearest neighbors to use. Defaults to 5.\n",
    "        epsilon (float, optional): A small positive constant for the calculation. Defaults to 0.1.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: A scalar tensor representing the estimated dual value.\n",
    "        \"\"\"\n",
    "        # Get dimensions from input tensors\n",
    "        n, _ = X_tensor.shape\n",
    "        m, _ = U_tensor.shape\n",
    "\n",
    "        dists = torch.cdist(X_tensor, X_tensor, p=2) # Shape: [n, n] [i, j] = ||x_i - x_j||^2\n",
    "        _, topk_indices = torch.topk(dists, k, dim=1, largest=False)\n",
    "        neighbor_indices = topk_indices[:, :]  # Shape: [n, k]\n",
    "        Y_neighbors = Y_tensor[neighbor_indices]  # Shape: [n, k, q] [i, k] = y_i^k\n",
    "\n",
    "        U_expanded = U_tensor.unsqueeze(1).expand(-1, n, -1)  # Shape: [m, n, q] [i, :, :] = u_i\n",
    "        X_expanded_for_U = X_tensor.unsqueeze(0).expand(m, -1, -1)  # Shape: [m, n, p] [:, i, :] = x_i\n",
    "        UX = torch.cat((X_expanded_for_U, U_expanded), dim=-1) # Shape: [m, n, q + p] [i, j] = torch.cat[u_i, x_j]\n",
    "\n",
    "        X_expanded_for_Y = X_tensor.unsqueeze(1).expand(-1, k, -1) # Shape: [n, k, p]\n",
    "        YX = torch.cat((X_expanded_for_Y, Y_neighbors), dim=-1) # Shape: [n, k, p + q] [i, j] = torch.cat[x_i, y_i^k]\n",
    "\n",
    "        phi_vals = phi_net(UX).squeeze(-1)  # Shape: [m, n] [i, j] = phi(u_i, x_j)\n",
    "        psi_vals = psi_net(YX).squeeze(-1)  # Shape: [n, k] [i, j] = psi(x_j, y_j^k)\n",
    "        einsum_term = torch.einsum('mq,nkq->mnk', U_tensor, Y_neighbors) # Shape: [m, n, k]\n",
    "\n",
    "        phi_vals_expanded = phi_vals.unsqueeze(-1)  # Shape: [m, n, 1]\n",
    "        psi_vals_expanded = psi_vals.unsqueeze(0)   # Shape: [1, n, k]\n",
    "\n",
    "        slackness = ( einsum_term - phi_vals_expanded - psi_vals_expanded )\n",
    "        exponent_val = torch.exp(slackness / epsilon )\n",
    "        dual_estimate = epsilon * torch.mean( exponent_val )\n",
    "        return dual_estimate\n",
    "\n",
    "\n",
    "for epoch_idx in range(1, num_epochs):\n",
    "\n",
    "        phi_network.zero_grad()\n",
    "        psi_network.zero_grad()\n",
    "\n",
    "        yindexes = torch.randint(0, dataset_size, (batch_size,))\n",
    "        entropy_indexes = torch.randint(0, dataset_size, (16,))\n",
    "\n",
    "        X_batch = X_tensor[yindexes]\n",
    "        Y_batch = Y_tensor[yindexes]\n",
    "        U_batch = torch.randn(\n",
    "                batch_size, Y_batch.shape[1],\n",
    "                **device_and_dtype_specifications\n",
    "        )\n",
    "\n",
    "        phi = phi_network(torch.cat([X_batch, U_batch], dim=1))\n",
    "        psi = psi_network(torch.cat([X_batch, Y_batch], dim=1))\n",
    "\n",
    "        entropy = estimate_entropy_dual(\n",
    "                X_tensor=X_tensor[entropy_indexes],\n",
    "                Y_tensor=Y_tensor[entropy_indexes],\n",
    "                U_tensor=U_batch,\n",
    "                phi_net=phi_network,\n",
    "                psi_net=psi_network,\n",
    "                k=1,\n",
    "                epsilon=epsilon\n",
    "        )\n",
    "        objective = torch.mean(phi) + torch.mean(psi) + entropy\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(phi_network.parameters(), max_norm=1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(psi_network.parameters(), max_norm=1.0)\n",
    "\n",
    "        objective.backward()\n",
    "        phi_network_optimizer.step()\n",
    "        psi_network_optimizer.step()\n",
    "        print(objective.item(), epoch_idx, epsilon)\n",
    "\n",
    "_ = phi_network.eval()\n",
    "_ = psi_network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd9346b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "number_of_points_to_visualize = 1000\n",
    "\n",
    "with torch.no_grad():\n",
    "        U_tensor = torch.randn(number_of_points_to_visualize, d, **device_and_dtype_specifications)\n",
    "        UX_tensor = X_tensor[125:126].repeat(number_of_points_to_visualize, 1)\n",
    "        potential_tensor = phi_network(torch.cat([UX_tensor, U_tensor], dim=1))\n",
    "\n",
    "potential = potential_tensor.detach().cpu().numpy()\n",
    "U = U_tensor.detach().cpu().numpy()\n",
    "scatter = ax.scatter(U[:, 0], U[:, 1], potential.squeeze(), color='red', marker='o', s=30, alpha=0.6)\n",
    "ax.grid(True)\n",
    "\n",
    "ax.view_init(elev=20, azim=120)\n",
    "ax.set_xlabel('u1')\n",
    "ax.set_ylabel('u2')\n",
    "ax.set_zlabel('phi_u')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4155d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to %matplotlib qt to have interactive plots\n",
    "%matplotlib qt\n",
    "\n",
    "from data_utils import create_conditional_x\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10), subplot_kw={'projection': '3d'})\n",
    "fig.suptitle('Separated 3D Plots', fontsize=16)\n",
    "\n",
    "ax1.set_title('Conditional Scatter Data (y_x_gt)')\n",
    "ax1.set_xlabel('Axis 0')\n",
    "ax1.set_ylabel('Axis 1')\n",
    "ax1.set_zlabel('x_ value')\n",
    "\n",
    "for x_ in range(50, 250, 10):\n",
    "    x = np.array([x_ / 100])[:, None]\n",
    "\n",
    "    # This section is now active for the first plot\n",
    "    _, y_x_gt = create_conditional_x(n_points=100, x_value=x_/100)\n",
    "    z_scatter = np.full(y_x_gt.shape[0], x)\n",
    "    ax1.scatter(y_x_gt[:, 0], y_x_gt[:, 1], z_scatter, color='blue', marker='o', s=30, alpha=0.2)\n",
    "\n",
    "ax1.view_init(elev=-55, azim=154, roll=-83)\n",
    "\n",
    "ax2.set_title('Contour Lines')\n",
    "ax2.set_xlabel('Axis 0')\n",
    "ax2.set_ylabel('Axis 1')\n",
    "ax2.set_zlabel('x_ value')\n",
    "\n",
    "loop_start_value = 50\n",
    "for x_ in range(loop_start_value, 250, 10):\n",
    "\n",
    "    x = torch.tensor([x_ / 100], **device_and_dtype_specifications)[:, None]\n",
    "    x = x.repeat(repeats=(100, 1))\n",
    "\n",
    "    colors = ['red', 'purple', 'green', 'orange']\n",
    "    radii = [0.1, 0.5, 1., 1.5]\n",
    "    for contour_radius, color in zip(radii, colors):\n",
    "        pi_tensor = torch.linspace(-torch.pi, torch.pi, 100)\n",
    "        u_tensor = torch.stack([\n",
    "            contour_radius * torch.cos(pi_tensor),\n",
    "            contour_radius * torch.sin(pi_tensor),\n",
    "        ], dim=1)\n",
    "\n",
    "        u_tensor = u_tensor.to(**device_and_dtype_specifications)\n",
    "        u_tensor.requires_grad = True\n",
    "\n",
    "        potential = phi_network(torch.cat([x, u_tensor], dim=1))\n",
    "        pushforward_of_u = torch.autograd.grad(potential.sum(), u_tensor)[0]\n",
    "\n",
    "        z_line = x.detach().cpu().numpy()\n",
    "        label = f'Radius {contour_radius}' if x_ == loop_start_value else \"\"\n",
    "        ax1.plot(pushforward_of_u[:, 0], pushforward_of_u[:, 1], z_line, color=color, linewidth=2.5, label=label)\n",
    "        ax2.plot(pushforward_of_u[:, 0], pushforward_of_u[:, 1], z_line, color=color, linewidth=2.5, label=label)\n",
    "\n",
    "ax2.view_init(elev=-55, azim=154, roll=-83)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make room for suptitle\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector_quantile_regression",
   "language": "python",
   "name": "vector_quantile_regression"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
