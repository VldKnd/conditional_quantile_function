{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138531b2",
   "metadata": {},
   "source": [
    "Relaxed entropy dual with normal feed forward nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "490bdd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class BetaNetwork(torch.nn.Module):\n",
    "    \"\"\"Input Convex Neural Network for beta potential estimation\"\"\"\n",
    "\n",
    "    def __init__(self, input_dimension: int, hidden_dimension: int, num_hidden_layers: int, output_dimension: int):\n",
    "        super().__init__()\n",
    "\n",
    "        Wzs = []\n",
    "        Wzs.append(nn.Linear(input_dimension, hidden_dimension))\n",
    "        for _ in range(num_hidden_layers - 1):\n",
    "            Wzs.append(torch.nn.Linear(hidden_dimension, hidden_dimension, bias=False))\n",
    "        Wzs.append(torch.nn.Linear(hidden_dimension, 1, bias=False))\n",
    "        self.Wzs = torch.nn.ModuleList(Wzs)\n",
    "\n",
    "        Wxs = []\n",
    "        for _ in range(num_hidden_layers - 1):\n",
    "            Wxs.append(nn.Linear(input_dimension, hidden_dimension))\n",
    "        Wxs.append(nn.Linear(input_dimension, output_dimension, bias=False))\n",
    "        self.Wxs = torch.nn.ModuleList(Wxs)\n",
    "        self.act = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.act(self.Wzs[0](x))\n",
    "        for Wz, Wx in zip(self.Wzs[1:-1], self.Wxs[:-1]):\n",
    "            z = self.act(Wz(z) + Wx(x))\n",
    "        return self.Wzs[-1](z) + self.Wxs[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915bff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_sphere_uniform(n, d, **kwargs):\n",
    "    \"\"\"Generate n points inside the d-dimensional sphere.\"\"\"\n",
    "    random_vectors = torch.randn(n, d, **kwargs)\n",
    "    vectors_norms = torch.norm(random_vectors, dim=1, keepdim=True)\n",
    "    radius = torch.pow(torch.rand(n, 1, **kwargs), 1. / d)\n",
    "    return radius * random_vectors / vectors_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec1fae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import create_joint_x_y\n",
    "import numpy as np\n",
    "\n",
    "num_points_to_generate = 1000\n",
    "X, Y = create_joint_x_y(num_points_to_generate)\n",
    "\n",
    "n, d = Y.shape\n",
    "m = n\n",
    "\n",
    "nu = np.ones((n, 1)) / n\n",
    "mu = np.ones((m, 1)) / m\n",
    "\n",
    "phi_network = nn.Sequential(\n",
    "    nn.Linear(d + X.shape[1], 100),\n",
    "    nn.Softplus(),\n",
    "    nn.Linear(100, 1)\n",
    ")\n",
    "psi_network = nn.Sequential(\n",
    "    nn.Linear(d + X.shape[1], 100),\n",
    "    nn.Softplus(),\n",
    "    nn.Linear(100, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e63dc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf 1\n",
      "nan 2\n",
      "nan 3\n",
      "nan 4\n",
      "nan 5\n",
      "nan 6\n",
      "nan 7\n",
      "nan 8\n",
      "nan 9\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device_and_dtype_specifications = dict(dtype=torch.float64, device=torch.device(\"cpu\"))\n",
    "epsilon = 0.01\n",
    "num_epochs = 10\n",
    "\n",
    "phi_network.to(**device_and_dtype_specifications)\n",
    "psi_network.to(**device_and_dtype_specifications)\n",
    "\n",
    "phi_network_optimizer = torch.optim.Adam([dict(params=phi_network.parameters())], lr=0.01)\n",
    "psi_network_optimizer = torch.optim.Adam([dict(params=psi_network.parameters())], lr=0.01)\n",
    "\n",
    "X, Y = create_joint_x_y(num_points_to_generate)\n",
    "X_tensor = torch.tensor(X, **device_and_dtype_specifications)\n",
    "Y_tensor = torch.tensor(Y, **device_and_dtype_specifications)\n",
    "# U_tensor = torch_sphere_uniform(num_points_to_generate, Y.shape[1], **device_and_dtype_specifications)\n",
    "dataset_size = num_points_to_generate\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "def estimate_entropy_dual(X_tensor, Y_tensor, U_tensor, phi_net, psi_net, k=5, epsilon=0.1, use_log=True):\n",
    "        \"\"\"\n",
    "        Estimate the dual objective term for entropy estimation.\n",
    "\n",
    "        This function implements the core calculation based on nearest neighbors and learned\n",
    "        potential functions phi and psi. It offers an option to oversample some x's to better approximate P(Y|X)\n",
    "\n",
    "        Args:\n",
    "        X_tensor (torch.Tensor): The input tensor for x, with shape [n, p].\n",
    "        Y_tensor (torch.Tensor): The input tensor for y, with shape [n, q].\n",
    "        U_tensor (torch.Tensor): The tensor of oversampled variables u, with shape [m, q].\n",
    "        phi_net (nn.Module): The neural network representing the potential function phi(u, x).\n",
    "        psi_net (nn.Module): The neural network representing the potential function psi(x, y).\n",
    "        k (int, optional): The number of nearest neighbors to use. Defaults to 5.\n",
    "        epsilon (float, optional): A small positive constant for the calculation. Defaults to 0.1.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: A scalar tensor representing the estimated dual value.\n",
    "        \"\"\"\n",
    "        # Get dimensions from input tensors\n",
    "        n, _ = X_tensor.shape\n",
    "        m, _ = U_tensor.shape\n",
    "\n",
    "        dists = torch.cdist(X_tensor, X_tensor, p=2) # Shape: [n, n] [i, j] = ||x_i - x_j||^2\n",
    "        _, topk_indices = torch.topk(dists, k, dim=1, largest=False)\n",
    "        neighbor_indices = topk_indices[:, :]  # Shape: [n, k]\n",
    "        Y_neighbors = Y_tensor[neighbor_indices]  # Shape: [n, k, q] [i, k] = y_i^k\n",
    "\n",
    "        U_expanded = U_tensor.unsqueeze(1).expand(-1, n, -1)  # Shape: [m, n, q] [i, :, :] = u_i\n",
    "        X_expanded_for_U = X_tensor.unsqueeze(0).expand(m, -1, -1)  # Shape: [m, n, p] [:, i, :] = x_i\n",
    "        UX = torch.cat((X_expanded_for_U, U_expanded), dim=-1) # Shape: [m, n, q + p] [i, j] = torch.cat[u_i, x_j]\n",
    "\n",
    "        X_expanded_for_Y = X_tensor.unsqueeze(1).expand(-1, k, -1) # Shape: [n, k, p]\n",
    "        YX = torch.cat((X_expanded_for_Y, Y_neighbors), dim=-1) # Shape: [n, k, p + q] [i, j] = torch.cat[x_i, y_i^k]\n",
    "\n",
    "        phi_vals = phi_net(UX).squeeze(-1)  # Shape: [m, n] [i, j] = phi(u_i, x_j)\n",
    "        psi_vals = psi_net(YX).squeeze(-1)  # Shape: [n, k] [i, j] = psi(x_j, y_j^k)\n",
    "        einsum_term = torch.einsum('mq,nkq->mnk', U_tensor, Y_neighbors) # Shape: [m, n, k]\n",
    "\n",
    "        phi_vals_expanded = phi_vals.unsqueeze(-1)  # Shape: [m, n, 1]\n",
    "        psi_vals_expanded = psi_vals.unsqueeze(0)   # Shape: [1, n, k]\n",
    "\n",
    "        slackness = ( einsum_term - phi_vals_expanded - psi_vals_expanded )\n",
    "        max_slackness = torch.max(slackness)\n",
    "        exponent_val = torch.exp((slackness - max_slackness) / epsilon )\n",
    "        dual_estimate = epsilon * torch.mean( exponent_val ) * torch.exp(max_slackness / epsilon)\n",
    "        return dual_estimate\n",
    "\n",
    "\n",
    "for epoch_idx in range(1, num_epochs):\n",
    "\n",
    "        phi_network.zero_grad()\n",
    "        psi_network.zero_grad()\n",
    "\n",
    "        yindexes = torch.randint(0, dataset_size, (batch_size,))\n",
    "        entropy_indexes = torch.randint(0, dataset_size, (16,))\n",
    "\n",
    "        X_batch = X_tensor[yindexes]\n",
    "        Y_batch = Y_tensor[yindexes]\n",
    "        U_batch = torch.randn(\n",
    "                batch_size, Y_batch.shape[1],\n",
    "                **device_and_dtype_specifications\n",
    "        )\n",
    "\n",
    "        phi = phi_network(torch.cat([X_batch, U_batch], dim=1))\n",
    "        psi = psi_network(torch.cat([X_batch, Y_batch], dim=1))\n",
    "\n",
    "        entropy = estimate_entropy_dual(\n",
    "                X_tensor=X_tensor[entropy_indexes],\n",
    "                Y_tensor=Y_tensor[entropy_indexes],\n",
    "                U_tensor=U_batch,\n",
    "                phi_net=phi_network,\n",
    "                psi_net=psi_network,\n",
    "                k=1,\n",
    "                epsilon=epsilon,\n",
    "                use_log=True\n",
    "        )\n",
    "        objective = torch.mean(phi) + torch.mean(psi) + entropy\n",
    "\n",
    "        objective.backward()\n",
    "        phi_network_optimizer.step()\n",
    "        psi_network_optimizer.step()\n",
    "        print(objective.item(), epoch_idx)\n",
    "\n",
    "_ = phi_network.eval()\n",
    "_ = psi_network.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector_quantile_regression",
   "language": "python",
   "name": "vector_quantile_regression"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
