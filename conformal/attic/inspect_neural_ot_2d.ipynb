{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (768, 8) (768, 2)\n",
      "[NeuralOT] Fitting on residuals: train=96, calib=96, y_dim=2\n",
      "[NeuralOT] Initializing amortized UOTQR: device=cuda, dtype=float32, x_dim=8, y_dim=2, epochs=200, batch=256, hidden_dim=32, layers=2\n",
      "[NeuralOT] Starting training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Potential Objective: 13960.698, Amortization Objective: 3.558:   4%|‚ñç         | 8/200 [00:09<04:36,  1.44s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "# Import Neural OT CP (same import style as other scripts here)\n",
    "from conformal.neural_ot_predictors import NeuralOTCPScore\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Config (Jupyter-friendly)\n",
    "# -----------------------------\n",
    "CONFIG: Dict = {\n",
    "    \"dataset_name\": \"enb\",  # 2D output dataset\n",
    "    \"alpha\": 0.9,\n",
    "    \"seed\": 567,\n",
    "    \"test_size\": 0.5,  # split for test; then we'll split test into cal/test equally\n",
    "    \"neural_ot\": {\n",
    "        \"number_of_hidden_layers\": 2,\n",
    "        \"z_dimension\": 32,\n",
    "        \"batch_size\": 256,\n",
    "        \"num_epochs\": 500,\n",
    "        \"lr\": 1e-3,\n",
    "        \"device\": None,     # auto-selects CUDA if available when None\n",
    "        \"dtype\": \"float32\",\n",
    "    },\n",
    "    \"viz\": {\n",
    "        \"figsize\": (10, 4),\n",
    "        \"bins\": 60,\n",
    "        \"alpha_points\": 0.35,\n",
    "        \"alpha_hist\": 0.35,\n",
    "        \"save_dir\": \"outputs/ot_neural_inspect\",\n",
    "        \"prefix\": \"enb_residual_uniformity\",\n",
    "        \"save\": False,\n",
    "        \"show\": True,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Data utilities\n",
    "# -----------------------------\n",
    "\n",
    "def load_real_dataframe(name: str) -> pd.DataFrame:\n",
    "    \"\"\"Load a real dataset by name.\n",
    "\n",
    "    Tries, in order:\n",
    "    - regression_refactored/data/{name}.arff\n",
    "    - OTCP/data/{name}.arff\n",
    "    - regression_refactored/csv/{name}.csv\n",
    "    \"\"\"\n",
    "    repo_root = \"/home/labcmap/mahmoud.hegazy/conditional_quantile_function\"\n",
    "\n",
    "    candidates = [\n",
    "        os.path.join(repo_root, \"regression_refactored\", \"data\", f\"{name}.arff\"),\n",
    "        os.path.join(repo_root, \"OTCP\", \"data\", f\"{name}.arff\"),\n",
    "    ]\n",
    "\n",
    "    # Try ARFF first\n",
    "    for arff_path in candidates:\n",
    "        if os.path.exists(arff_path):\n",
    "            from scipy.io import arff  # type: ignore\n",
    "            data, _ = arff.loadarff(arff_path)\n",
    "            df = pd.DataFrame(data)\n",
    "            return df.dropna()\n",
    "\n",
    "    # Fallback to CSV\n",
    "    csv_path = os.path.join(repo_root, \"regression_refactored\", \"csv\", f\"{name}.csv\")\n",
    "    if os.path.exists(csv_path):\n",
    "        return pd.read_csv(csv_path).dropna()\n",
    "\n",
    "    raise FileNotFoundError(f\"Could not find dataset {name} in known locations.\")\n",
    "\n",
    "\n",
    "def get_xy_from_df(df: pd.DataFrame, y_dim: int = 2) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Split dataframe into features X and responses Y, taking the last y_dim columns as Y.\"\"\"\n",
    "    y = df[df.columns[-y_dim:]].values\n",
    "    x = df[df.columns[:-y_dim]].values\n",
    "    return x.astype(np.float64), y.astype(np.float64)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Math helpers\n",
    "# -----------------------------\n",
    "\n",
    "def chi2_radius_2d(alphas: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"For 2D standard normal U, radius r such that P(||U|| <= r) = alpha.\n",
    "    Since R^2 ~ ChiSquare(df=2), CDF(R) = 1 - exp(-r^2/2) => r = sqrt(-2 log(1 - alpha)).\n",
    "    \"\"\"\n",
    "    alphas = np.clip(alphas, 1e-6, 1 - 1e-6)\n",
    "    return np.sqrt(-2.0 * np.log(1.0 - alphas))\n",
    "\n",
    "\n",
    "def make_circle_points(radius: float, num_angles: int = 256) -> np.ndarray:\n",
    "    thetas = np.linspace(0, 2 * np.pi, num_angles, endpoint=False)\n",
    "    return np.stack([radius * np.cos(thetas), radius * np.sin(thetas)], axis=-1)\n",
    "\n",
    "\n",
    "def standard_normal_pdf(x: np.ndarray) -> np.ndarray:\n",
    "    return (1.0 / np.sqrt(2.0 * np.pi)) * np.exp(-0.5 * x**2)\n",
    "\n",
    "\n",
    "def rayleigh_pdf(r: np.ndarray) -> np.ndarray:\n",
    "    # Rayleigh(sigma=1) is the norm distribution of 2D Normal(0, I)\n",
    "    return r * np.exp(-0.5 * r**2)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Training utilities\n",
    "# -----------------------------\n",
    "\n",
    "def train_models(x: np.ndarray, y: np.ndarray, config: Dict):\n",
    "    seed = config.get(\"seed\", 567)\n",
    "    test_size = config.get(\"test_size\", 0.5)\n",
    "    alpha = config.get(\"alpha\", 0.9)\n",
    "\n",
    "    # Split: train vs test, then test split into cal/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=seed)\n",
    "    X_test, X_cal, y_test, y_cal = train_test_split(X_test, y_test, test_size=0.5, random_state=seed)\n",
    "\n",
    "    # Base regressor for residuals\n",
    "    base = RandomForestRegressor(random_state=seed)\n",
    "    base.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = base.predict(X_train)\n",
    "    y_pred_cal = base.predict(X_cal)\n",
    "    y_pred_test = base.predict(X_test)\n",
    "\n",
    "    # Neural OT model on residual scores\n",
    "    neural_cfg = dict(config.get(\"neural_ot\", {}))\n",
    "    neural = NeuralOTCPScore(alpha=alpha, nn_kwargs=neural_cfg)\n",
    "    neural.fit(X_cal, y_cal, y_pred_cal)\n",
    "\n",
    "    return {\n",
    "        \"base\": base,\n",
    "        \"neural\": neural,\n",
    "        \"splits\": {\n",
    "            \"X_train\": X_train,\n",
    "            \"y_train\": y_train,\n",
    "            \"X_cal\": X_cal,\n",
    "            \"y_cal\": y_cal,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred_train\": y_pred_train,\n",
    "            \"y_pred_cal\": y_pred_cal,\n",
    "            \"y_pred_test\": y_pred_test,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_residuals(models: Dict) -> Dict[str, np.ndarray]:\n",
    "    X_train = models[\"splits\"][\"X_train\"]\n",
    "    y_train = models[\"splits\"][\"y_train\"]\n",
    "    y_pred_train = models[\"splits\"][\"y_pred_train\"]\n",
    "\n",
    "    X_test = models[\"splits\"][\"X_test\"]\n",
    "    y_test = models[\"splits\"][\"y_test\"]\n",
    "    y_pred_test = models[\"splits\"][\"y_pred_test\"]\n",
    "\n",
    "    S_train = y_train - y_pred_train\n",
    "    S_test = y_test - y_pred_test\n",
    "\n",
    "    return {\"S_train\": S_train, \"S_test\": S_test, \"X_train\": X_train, \"X_test\": X_test}\n",
    "\n",
    "\n",
    "def push_residuals_to_U(models: Dict, S: np.ndarray, X: np.ndarray) -> np.ndarray:\n",
    "    import torch\n",
    "    neural = models[\"neural\"].model_\n",
    "\n",
    "    # Device/dtype from model\n",
    "    p = next(neural.parameters())\n",
    "    device = p.device\n",
    "    dtype = p.dtype\n",
    "\n",
    "    X_t = torch.from_numpy(X).to(device=device, dtype=dtype)\n",
    "    S_t = torch.from_numpy(S).to(device=device, dtype=dtype)\n",
    "    with torch.no_grad():\n",
    "        U_hat_t = neural.push_y_given_x(y=S_t, x=X_t)\n",
    "    return U_hat_t.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Plotting utilities\n",
    "# -----------------------------\n",
    "\n",
    "def plot_scatter_before_after(S_train: np.ndarray, S_test: np.ndarray, U_train: np.ndarray, U_test: np.ndarray, viz: Dict):\n",
    "    figsize = tuple(viz.get(\"figsize\", (10, 4)))\n",
    "    a_pts = float(viz.get(\"alpha_points\", 0.35))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "    axes[0].set_title(\"Residuals S (train/test)\")\n",
    "    axes[0].scatter(S_train[:, 0], S_train[:, 1], s=6, alpha=a_pts, label=\"train\")\n",
    "    axes[0].scatter(S_test[:, 0], S_test[:, 1], s=6, alpha=a_pts, label=\"test\")\n",
    "    axes[0].set_aspect(\"equal\", adjustable=\"box\")\n",
    "    axes[0].legend(markerscale=3)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[1].set_title(\"Pushed residuals U_hat = T_x(S) (train/test)\")\n",
    "    axes[1].scatter(U_train[:, 0], U_train[:, 1], s=6, alpha=a_pts, label=\"train\")\n",
    "    axes[1].scatter(U_test[:, 0], U_test[:, 1], s=6, alpha=a_pts, label=\"test\")\n",
    "    axes[1].set_aspect(\"equal\", adjustable=\"box\")\n",
    "    axes[1].legend(markerscale=3)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_marginals(U_train: np.ndarray, U_test: np.ndarray, viz: Dict):\n",
    "    # Overlay standard normal pdf on histograms of each coordinate\n",
    "    figsize = tuple(viz.get(\"figsize\", (10, 4)))\n",
    "    bins = int(viz.get(\"bins\", 60))\n",
    "    a_hist = float(viz.get(\"alpha_hist\", 0.35))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "    for d in range(2):\n",
    "        ax = axes[d]\n",
    "        ax.set_title(f\"U coord {d} ~ N(0,1)?\")\n",
    "        data_train = U_train[:, d]\n",
    "        data_test = U_test[:, d]\n",
    "\n",
    "        rng = np.linspace(min(data_train.min(), data_test.min()), max(data_train.max(), data_test.max()), 400)\n",
    "        pdf = standard_normal_pdf(rng)\n",
    "\n",
    "        ax.hist(data_train, bins=bins, density=True, alpha=a_hist, label=\"train\")\n",
    "        ax.hist(data_test, bins=bins, density=True, alpha=a_hist, label=\"test\")\n",
    "        ax.plot(rng, pdf, \"k--\", label=\"N(0,1) PDF\")\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_radius(U_train: np.ndarray, U_test: np.ndarray, viz: Dict):\n",
    "    # Norm radius distribution vs Rayleigh(sigma=1)\n",
    "    figsize = tuple(viz.get(\"figsize\", (10, 4)))\n",
    "    bins = int(viz.get(\"bins\", 60))\n",
    "    a_hist = float(viz.get(\"alpha_hist\", 0.35))\n",
    "\n",
    "    r_train = np.linalg.norm(U_train, axis=1)\n",
    "    r_test = np.linalg.norm(U_test, axis=1)\n",
    "\n",
    "    r_max = max(r_train.max(), r_test.max())\n",
    "    rng = np.linspace(0.0, r_max, 400)\n",
    "    pdf = rayleigh_pdf(rng)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    ax.set_title(\"||U|| distribution vs Rayleigh(1)\")\n",
    "    ax.hist(r_train, bins=bins, density=True, alpha=a_hist, label=\"train\")\n",
    "    ax.hist(r_test, bins=bins, density=True, alpha=a_hist, label=\"test\")\n",
    "    ax.plot(rng, pdf, \"k--\", label=\"Rayleigh PDF\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# %%\n",
    "# Reproducibility\n",
    "np.random.seed(CONFIG.get(\"seed\", 567))\n",
    "\n",
    "# %%\n",
    "# Load data and split X, Y (last 2 columns as Y)\n",
    "df = load_real_dataframe(CONFIG.get(\"dataset_name\", \"enb\"))\n",
    "x, y = get_xy_from_df(df, y_dim=2)\n",
    "print(\"Shapes:\", x.shape, y.shape)\n",
    "\n",
    "# %%\n",
    "# Train RF + NeuralOT on residuals\n",
    "models = train_models(x, y, CONFIG)\n",
    "\n",
    "# %%\n",
    "# Compute residuals for train and test, then push through OT to latent U\n",
    "parts = compute_residuals(models)\n",
    "S_train, S_test = parts[\"S_train\"], parts[\"S_test\"]\n",
    "U_train = push_residuals_to_U(models, S_train, parts[\"X_train\"])\n",
    "U_test = push_residuals_to_U(models, S_test, parts[\"X_test\"])\n",
    "\n",
    "# %%\n",
    "# Scatter before/after\n",
    "fig1 = plot_scatter_before_after(S_train, S_test, U_train, U_test, CONFIG.get(\"viz\", {}))\n",
    "\n",
    "# %%\n",
    "# Marginal histograms for pushed residuals vs N(0,1)\n",
    "fig2 = plot_marginals(U_train, U_test, CONFIG.get(\"viz\", {}))\n",
    "\n",
    "# %%\n",
    "# Radial histogram vs Rayleigh\n",
    "fig3 = plot_radius(U_train, U_test, CONFIG.get(\"viz\", {}))\n",
    "\n",
    "# %%\n",
    "# Optional save/show control\n",
    "viz = CONFIG.get(\"viz\", {})\n",
    "if viz.get(\"save\", False):\n",
    "    os.makedirs(viz.get(\"save_dir\", \"outputs/ot_neural_inspect\"), exist_ok=True)\n",
    "    prefix = viz.get(\"prefix\", \"enb_residual_uniformity\")\n",
    "    fig1.savefig(os.path.join(viz.get(\"save_dir\", \"outputs/ot_neural_inspect\"), f\"{prefix}_scatter.pdf\"), bbox_inches=\"tight\")\n",
    "    fig2.savefig(os.path.join(viz.get(\"save_dir\", \"outputs/ot_neural_inspect\"), f\"{prefix}_marginals.pdf\"), bbox_inches=\"tight\")\n",
    "    fig3.savefig(os.path.join(viz.get(\"save_dir\", \"outputs/ot_neural_inspect\"), f\"{prefix}_radius.pdf\"), bbox_inches=\"tight\")\n",
    "if viz.get(\"show\", True):\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close(fig1); plt.close(fig2); plt.close(fig3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "confot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
