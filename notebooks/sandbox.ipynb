{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c55e5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Index: 13029, objective: 1.233:  13%|█▎        | 13030/100000 [00:20<02:16, 635.45it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m     26\u001b[39m     u_potential = quadratic_potential(X_batch, U_batch)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m Y_approximated = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_potential\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mU_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     30\u001b[39m objective = torch.norm(\n\u001b[32m     31\u001b[39m     Y_batch - Y_approximated,\n\u001b[32m     32\u001b[39m     dim=-\u001b[32m1\u001b[39m\n\u001b[32m     33\u001b[39m )**\u001b[32m2\u001b[39m\n\u001b[32m     34\u001b[39m objective = objective.mean()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conditional_quantile_function/.venv/lib/python3.13/site-packages/torch/autograd/__init__.py:502\u001b[39m, in \u001b[36mgrad\u001b[39m\u001b[34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[39m\n\u001b[32m    498\u001b[39m     result = _vmap_internals._vmap(vjp, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, allow_none_pass_through=\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[32m    499\u001b[39m         grad_outputs_\n\u001b[32m    500\u001b[39m     )\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m502\u001b[39m     result = \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[32m    512\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m    513\u001b[39m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[32m    514\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[32m    515\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conditional_quantile_function/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import trange\n",
    "from datasets.synthetic.quadratic_potential import ConvexQuadraticPotential\n",
    "from datasets import BananaDataset\n",
    "\n",
    "tensor_parameters = {}\n",
    "dataset = BananaDataset(tensor_parameters)\n",
    "\n",
    "training_trace = []\n",
    "quadratic_potential = ConvexQuadraticPotential(\n",
    "    number_of_functions=10,\n",
    "    response_size=2,\n",
    "    covariate_size=1,\n",
    "    epsilon=1e-3,\n",
    ")\n",
    "quadratic_potential_optimizer = torch.optim.AdamW(params=quadratic_potential.parameters(), lr=1e-3)\n",
    "progress_bar = trange(10**5)\n",
    "\n",
    "for index in progress_bar:\n",
    "    quadratic_potential_optimizer.zero_grad()\n",
    "    U_batch = torch.randn(256, 2).requires_grad_(True)\n",
    "    X_batch = torch.rand(256, 1)*2 + 0.5\n",
    "    Y_batch = dataset.push_u_given_x(u=U_batch, x=X_batch)\n",
    "    \n",
    "    with torch.enable_grad():\n",
    "        u_potential = quadratic_potential(X_batch, U_batch)\n",
    "\n",
    "    Y_approximated = torch.autograd.grad(u_potential.sum(), U_batch, retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "    objective = torch.norm(\n",
    "        Y_batch - Y_approximated,\n",
    "        dim=-1\n",
    "    )**2\n",
    "    objective = objective.mean()\n",
    "    objective.backward()\n",
    "    quadratic_potential_optimizer.step()\n",
    "    objective_item = objective.item()\n",
    "    training_trace.append(objective_item)\n",
    "    progress_bar.set_description(f\"Index: {index}, objective: {objective_item:.3f}\")\n",
    "print(f\"Objective: {torch.tensor(training_trace[-1000:]).mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d974e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.quantile import get_quantile_level_analytically\n",
    "\n",
    "for activation_functon_name, quadratic_potential in activation_function_name_to_quadratic_potential.items():\n",
    "    number_of_conditions = 100\n",
    "    dataset_size = 100\n",
    "    x = torch.rand(1, number_of_conditions, 1) * 2 + 0.5\n",
    "    x = x.repeat(dataset_size, 1, 1)\n",
    "    u = torch.randn(dataset_size, number_of_conditions, 2).requires_grad_(True)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10), subplot_kw={'projection': '3d'})\n",
    "    fig.suptitle('Separated 3D Plots', fontsize=16)\n",
    "\n",
    "    u_potential = quadratic_potential(x=x, u=u)\n",
    "    y_ground_truth = torch.autograd.grad(u_potential.sum(), u)[0]\n",
    "    y_ground_truth_0 = y_ground_truth[:, :, 0].flatten()\n",
    "    y_ground_truth_1 = y_ground_truth[:, :, 1].flatten()\n",
    "    z = x.flatten()\n",
    "    ax1.scatter(y_ground_truth_0, y_ground_truth_1, z, color='blue', marker='o', s=30, alpha=0.2)\n",
    "\n",
    "    color_map = matplotlib.colormaps['viridis']\n",
    "    number_of_quantile_levels = 10\n",
    "    quantile_levels = torch.linspace(0.05, 0.95, number_of_quantile_levels)\n",
    "    radii = get_quantile_level_analytically(quantile_levels, distribution=\"gaussian\", dimension=2)\n",
    "    colors = [color_map(i / len(radii)) for i in range(len(radii))]\n",
    "\n",
    "    for condition in torch.linspace(0.5, 2.5, 20):\n",
    "        for i, contour_radius in enumerate(radii):\n",
    "            color = colors[i]\n",
    "            pi = torch.linspace(-torch.pi, torch.pi, 1000)\n",
    "\n",
    "            u_quantile = torch.stack([\n",
    "                contour_radius * torch.cos(pi),\n",
    "                contour_radius * torch.sin(pi),\n",
    "            ]).T\n",
    "            u_quantile = u_quantile.to(**{}).requires_grad_(True)\n",
    "            x_quantile = torch.ones(u_quantile.shape[0], 1)*condition\n",
    "\n",
    "            u_quantile_potential = quadratic_potential(x=x_quantile, u=u_quantile)\n",
    "            y_quantile = torch.autograd.grad(u_quantile_potential.sum(), u_quantile)[0]\n",
    "            z_line = x_quantile.flatten()\n",
    "\n",
    "            label = f'Quantile level {quantile_levels[i]:.2f}'\n",
    "            ax2.plot(y_quantile[:, 0], y_quantile[:, 1], z_line, color=color, linewidth=2.5, label=label)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a278e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector-quantile-regression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
