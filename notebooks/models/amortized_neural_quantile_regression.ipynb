{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7182ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Potential Objective: 0.750, Amortization Objective: 0.486, LR: 0.000158:  70%|███████   | 7/10 [1:07:16<27:58, 559.48s/it]"
     ]
    }
   ],
   "source": [
    "from infrastructure.classes import Experiment, TrainParameters\n",
    "from infrastructure.training import train\n",
    "import torch\n",
    "\n",
    "experiment = Experiment(\n",
    "    tensor_parameters=dict(dtype=torch.float32, device=torch.device(\"cpu\")),\n",
    "    dataset_name=\"fnlvqr_glasses\",\n",
    "    dataset_number_of_points=10**6,\n",
    "    dataloader_parameters=dict(batch_size=256, shuffle=True),\n",
    "    pushforward_operator_name=\"amortized_neural_quantile_regression\",\n",
    "    pushforward_operator_parameters=dict(\n",
    "        feature_dimension=1,\n",
    "        response_dimension=1,\n",
    "        hidden_dimension=64,\n",
    "        number_of_hidden_layers=8,\n",
    "        activation_function_name=\"Softplus\",\n",
    "        network_type=\"PISCNN\",\n",
    "        potential_to_estimate_with_neural_network=\"u\"\n",
    "    ),\n",
    "    train_parameters=TrainParameters(\n",
    "        number_of_epochs_to_train=100,\n",
    "        verbose=True,\n",
    "        optimizer_parameters=dict(lr=0.01),\n",
    "        scheduler_parameters=dict(eta_min=0)\n",
    "    )\n",
    ")\n",
    "\n",
    "model = train(experiment)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6def3489",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1000x2 and 1x8)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PICNN_FNLVQR_Glasses\n\u001b[32m      4\u001b[39m dataset = PICNN_FNLVQR_Glasses(tensor_parameters=experiment.tensor_parameters)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mplot_quantile_levels_from_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconditional_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m.9\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnumber_of_quantile_levels\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensor_parameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor_parameters\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conditional_quantile_function/src/utils/plot.py:44\u001b[39m, in \u001b[36mplot_quantile_levels_from_dataset\u001b[39m\u001b[34m(model, dataset, conditional_value, number_of_quantile_levels, tensor_parameters)\u001b[39m\n\u001b[32m     34\u001b[39m pi = torch.linspace(-torch.pi, torch.pi, \u001b[32m1000\u001b[39m)\n\u001b[32m     36\u001b[39m ground_truth_U_quantiles = (\n\u001b[32m     37\u001b[39m     torch.stack(\n\u001b[32m     38\u001b[39m         [\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m     ).T\n\u001b[32m     43\u001b[39m ).to(**tensor_parameters)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m ground_truth_Y_quantiles = \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpush_u_given_x\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mu\u001b[49m\u001b[43m=\u001b[49m\u001b[43mground_truth_U_quantiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_batch\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.detach().cpu()\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     49\u001b[39m     approximated_U_quantiels = model.push_y_given_x(\n\u001b[32m     50\u001b[39m         y=ground_truth_Y_quantiles, x=X_batch\n\u001b[32m     51\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conditional_quantile_function/src/datasets/synthetic/convex/picnn/picnn_base_dataset.py:32\u001b[39m, in \u001b[36mPICNN_BaseDataset.push_u_given_x\u001b[39m\u001b[34m(self, u, x)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpush_u_given_x\u001b[39m(\u001b[38;5;28mself\u001b[39m, u: torch.Tensor, x: torch.Tensor) -> torch.Tensor:\n\u001b[32m     29\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    Push forward the conditional distribution of the covariates given the response.\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpush_u_given_x\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conditional_quantile_function/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conditional_quantile_function/src/pushforward_operators/neural_quantile_regression/amortized_neural_quantile_regression.py:347\u001b[39m, in \u001b[36mAmortizedNeuralQuantileRegression.push_u_given_x\u001b[39m\u001b[34m(self, u, x, y_initial)\u001b[39m\n\u001b[32m    344\u001b[39m X_tensor = x\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.potential_to_estimate_with_neural_network == \u001b[33m\"\u001b[39m\u001b[33mu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m     Y_tensor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgradient_inverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    349\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y_initial \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conditional_quantile_function/src/pushforward_operators/neural_quantile_regression/amortized_neural_quantile_regression.py:129\u001b[39m, in \u001b[36mAmortizedNeuralQuantileRegression.gradient_inverse\u001b[39m\u001b[34m(self, condition_tensor, point_tensor)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgradient_inverse\u001b[39m(\n\u001b[32m    125\u001b[39m     \u001b[38;5;28mself\u001b[39m, condition_tensor: torch.Tensor, point_tensor: torch.Tensor\n\u001b[32m    126\u001b[39m ):\n\u001b[32m    127\u001b[39m     requires_grad_backup, point_tensor.requires_grad = point_tensor.requires_grad, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    128\u001b[39m     inverse_tensor = torch.autograd.grad(\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpotential_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoint_tensor\u001b[49m\u001b[43m)\u001b[49m.sum(),\n\u001b[32m    130\u001b[39m         point_tensor,\n\u001b[32m    131\u001b[39m         create_graph=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    132\u001b[39m     )[\u001b[32m0\u001b[39m]\n\u001b[32m    133\u001b[39m     point_tensor.requires_grad = requires_grad_backup\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inverse_tensor.detach()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conditional_quantile_function/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conditional_quantile_function/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conditional_quantile_function/src/pushforward_operators/picnn.py:136\u001b[39m, in \u001b[36mPISCNN.forward\u001b[39m\u001b[34m(self, condition, tensor)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, condition: torch.Tensor, tensor: torch.Tensor):\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     output = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output + \u001b[32m0.5\u001b[39m * torch.exp(\u001b[38;5;28mself\u001b[39m.log_alpha\n\u001b[32m    138\u001b[39m                                     ) * torch.norm(tensor, dim=-\u001b[32m1\u001b[39m, keepdim=\u001b[38;5;28;01mTrue\u001b[39;00m)**\u001b[32m2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conditional_quantile_function/src/pushforward_operators/picnn.py:94\u001b[39m, in \u001b[36mPICNN.forward\u001b[39m\u001b[34m(self, condition, tensor)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, condition: torch.Tensor, tensor: torch.Tensor):\n\u001b[32m     91\u001b[39m     \u001b[38;5;66;03m# First layer:\u001b[39;00m\n\u001b[32m     92\u001b[39m     u = \u001b[38;5;28mself\u001b[39m.u_activation(\u001b[38;5;28mself\u001b[39m.first_linear_layer_tilde(condition))\n\u001b[32m     93\u001b[39m     z = \u001b[38;5;28mself\u001b[39m.z_activation(\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfirst_linear_layer_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfirst_linear_layer_yu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m +\n\u001b[32m     95\u001b[39m         \u001b[38;5;28mself\u001b[39m.first_linear_layer_u(condition)\n\u001b[32m     96\u001b[39m     )\n\u001b[32m     98\u001b[39m     \u001b[38;5;66;03m# Iterations:\u001b[39;00m\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m iteration_number \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.number_of_hidden_layers):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conditional_quantile_function/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conditional_quantile_function/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conditional_quantile_function/.venv/lib/python3.13/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (1000x2 and 1x8)"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from utils.plot import plot_quantile_levels_from_dataset\n",
    "from datasets import PICNN_FNLVQR_Glasses\n",
    "dataset = PICNN_FNLVQR_Glasses(tensor_parameters=experiment.tensor_parameters)\n",
    "\n",
    "plot_quantile_levels_from_dataset(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    conditional_value=torch.Tensor([[.9]]),\n",
    "    number_of_quantile_levels=10,\n",
    "    tensor_parameters=experiment.tensor_parameters\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
